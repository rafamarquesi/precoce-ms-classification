
*****INICIO LOAD DATA******

*****INICIO PRINT INFOS******
Número total de linhas do DataFrame: 63072
Número de colunas: 112
Informações do DataFrame:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 63072 entries, 0 to 63071
Data columns (total 112 columns):
 #    Column                            Dtype         
---   ------                            -----         
 0    ID_ANIMAL                         uint32        
 1    EstabelecimentoMunicipio          category      
 2    DataAbate                         datetime64[ns]
 3    Frigorifico_ID                    uint8         
 4    Frigorifico_CNPJ                  uint64        
 5    Frigorifico_RazaoSocial           category      
 6    Municipio_Frigorifico             category      
 7    Tipificacao                       category      
 8    Maturidade                        category      
 9    Acabamento                        category      
 10   Peso                              float32       
 11   EstabelecimentoIdentificador      uint16        
 12   Data_homol                        datetime64[ns]
 13   Questionario_ID                   uint16        
 14   QuestionarioClassificacaoEstabel  uint8         
 15   FERTIIRRIGACAO                    uint8         
 16   ILP                               uint8         
 17   IFP                               uint8         
 18   ILPF                              uint8         
 19   CONCEN_VOLUM                      UInt8         
 20   CREEPFEEDING                      UInt8         
 21   FORN_ESTRAT_SILAGEM               UInt8         
 22   PROTEICO                          UInt8         
 23   PROTEICO_ENERGETICO               UInt8         
 24   RACAO_BAL_CONS_INFERIOR           UInt8         
 25   SAL_MINERAL                       UInt8         
 26   SALMINERAL_UREIA                  UInt8         
 27   RACAOO_BAL_CONSUMO_IG             UInt8         
 28   GRAO_INTEIRO                      UInt8         
 29   ALTO_CONCENTR_VOLUM               UInt8         
 30   ALTO_CONCENTRADO                  UInt8         
 31   QuestionarioPossuiOutrosIncentiv  uint8         
 32   QuestionarioFabricaRacao          uint8         
 33   area so confinamento              UInt8         
 34   regua de manejo                   UInt8         
 35   boa cobertura vegetal, com baixa  UInt8         
 36   erosaoo laminar ou em sulco igua  UInt8         
 37   identificacao individual          UInt8         
 38   rastreamento SISBOV               UInt8         
 39   Lista Trace                       UInt8         
 40   BPA                               UInt8         
 41   participa de aliancas mercadolog  UInt8         
 42   QuestionarioPraticaRecuperacaoPa  uint8         
 43   Confinamento                      UInt8         
 44   Suplementacao_a_campo             UInt8         
 45   SemiConfinamento                  UInt8         
 46   dif_datas                         uint16        
 47   DataAbate_6m_ANT                  datetime64[ns]
 48   data_homol_select                 datetime64[ns]
 49   data12m                           datetime64[ns]
 50   data6m                            datetime64[ns]
 51   data3m                            datetime64[ns]
 52   data1m                            datetime64[ns]
 53   data7d                            datetime64[ns]
 54   tot7d_Chuva                       float32       
 55   med7d_TempInst                    float32       
 56   med7d_TempMin                     float32       
 57   med7d_UmidInst                    float32       
 58   med7d_formITUinst                 float32       
 59   med7d_formITUmax                  float32       
 60   med7d_NDVI                        float32       
 61   med7d_EVI                         float32       
 62   med7d_preR_soja                   float32       
 63   med7d_preR_milho                  float32       
 64   med7d_preR_boi                    float32       
 65   tot1m_Chuva                       float32       
 66   med1m_TempInst                    float32       
 67   med1m_UmidInst                    float32       
 68   med1m_formITUinst                 float32       
 69   med1m_NDVI                        float32       
 70   med1m_EVI                         float32       
 71   med1m_preR_soja                   float32       
 72   med1m_preR_milho                  float32       
 73   med1m_preR_boi                    float32       
 74   tot3m_Chuva                       float32       
 75   med3m_TempInst                    float32       
 76   med3m_UmidInst                    float32       
 77   med3m_formITUinst                 float32       
 78   med3m_formITUmax                  float32       
 79   med3m_NDVI                        float32       
 80   med3m_EVI                         float32       
 81   med3m_preR_soja                   float32       
 82   med3m_preR_milho                  float32       
 83   med3m_preR_boi                    float32       
 84   tot6m_Chuva                       float32       
 85   med6m_TempInst                    float32       
 86   med6m_UmidInst                    float32       
 87   med6m_formITUinst                 float32       
 88   med6m_NDVI                        float32       
 89   med6m_EVI                         float32       
 90   med6m_preR_soja                   float32       
 91   med6m_preR_milho                  float32       
 92   med6m_preR_boi                    float32       
 93   tot12m_Chuva                      float32       
 94   med12m_TempInst                   float32       
 95   med12m_TempMin                    float32       
 96   med12m_UmidInst                   float32       
 97   med12m_formITUinst                float32       
 98   med12m_NDVI                       float32       
 99   med12m_EVI                        float32       
 100  med12m_preR_soja                  float32       
 101  med12m_preR_milho                 float32       
 102  med12m_preR_boi                   float32       
 103  cnt7d_CL_ITUinst                  float32       
 104  cnt1m_CL_ITUinst                  float32       
 105  cnt3m_CL_ITUinst                  float32       
 106  cnt6m_CL_ITUinst                  float32       
 107  cnt12m_CL_ITUinst                 float32       
 108  ANO                               uint16        
 109  CATEGORIA                         category      
 110  classificacao                     category      
 111  Motivo                            category      
dtypes: UInt8(24), category(9), datetime64[ns](9), float32(55), uint16(4), uint32(1), uint64(1), uint8(9)
memory usage: 22.7 MB
*****FIM PRINT INFOS*********
Function informations Took 0:00:00.012892

*****INICIO DELETE COLUNAS******
Coluna EstabelecimentoMunicipio excluída.
Coluna Frigorifico_ID excluída.
Coluna Frigorifico_CNPJ excluída.
Coluna Frigorifico_RazaoSocial excluída.
Coluna Municipio_Frigorifico excluída.
Coluna Maturidade excluída.
Coluna Acabamento excluída.
Coluna EstabelecimentoIdentificador excluída.
Coluna Questionario_ID excluída.
Coluna FERTIIRRIGACAO excluída.
Coluna CONCEN_VOLUM excluída.
Coluna CREEPFEEDING excluída.
Coluna FORN_ESTRAT_SILAGEM excluída.
Coluna PROTEICO excluída.
Coluna PROTEICO_ENERGETICO excluída.
Coluna RACAO_BAL_CONS_INFERIOR excluída.
Coluna SAL_MINERAL excluída.
Coluna SALMINERAL_UREIA excluída.
Coluna RACAOO_BAL_CONSUMO_IG excluída.
Coluna GRAO_INTEIRO excluída.
Coluna ALTO_CONCENTR_VOLUM excluída.
Coluna ALTO_CONCENTRADO excluída.
Coluna area so confinamento excluída.
Coluna boa cobertura vegetal, com baixa excluída.
Coluna erosaoo laminar ou em sulco igua excluída.
Coluna Lista Trace excluída.
Coluna BPA excluída.
Coluna dif_datas excluída.
Coluna tot7d_Chuva excluída.
Coluna med7d_TempInst excluída.
Coluna med7d_TempMin excluída.
Coluna med7d_UmidInst excluída.
Coluna med7d_formITUinst excluída.
Coluna med7d_formITUmax excluída.
Coluna med7d_NDVI excluída.
Coluna med7d_EVI excluída.
Coluna med7d_preR_soja excluída.
Coluna med7d_preR_milho excluída.
Coluna med7d_preR_boi excluída.
Coluna tot1m_Chuva excluída.
Coluna med1m_TempInst excluída.
Coluna med1m_UmidInst excluída.
Coluna med1m_formITUinst excluída.
Coluna med1m_NDVI excluída.
Coluna med1m_EVI excluída.
Coluna med1m_preR_soja excluída.
Coluna med1m_preR_milho excluída.
Coluna med1m_preR_boi excluída.
Coluna med3m_TempInst excluída.
Coluna med3m_UmidInst excluída.
Coluna med3m_formITUmax excluída.
Coluna med3m_EVI excluída.
Coluna med3m_preR_soja excluída.
Coluna tot6m_Chuva excluída.
Coluna med6m_TempInst excluída.
Coluna med6m_UmidInst excluída.
Coluna med6m_formITUinst excluída.
Coluna med6m_NDVI excluída.
Coluna med6m_EVI excluída.
Coluna med6m_preR_soja excluída.
Coluna med6m_preR_milho excluída.
Coluna med6m_preR_boi excluída.
Coluna tot12m_Chuva excluída.
Coluna med12m_TempInst excluída.
Coluna med12m_TempMin excluída.
Coluna med12m_UmidInst excluída.
Coluna med12m_formITUinst excluída.
Coluna med12m_NDVI excluída.
Coluna med12m_EVI excluída.
Coluna med12m_preR_soja excluída.
Coluna med12m_preR_milho excluída.
Coluna med12m_preR_boi excluída.
Coluna cnt7d_CL_ITUinst excluída.
Coluna cnt1m_CL_ITUinst excluída.
Coluna cnt3m_CL_ITUinst excluída.
Coluna cnt6m_CL_ITUinst excluída.
Coluna cnt12m_CL_ITUinst excluída.
Coluna ANO excluída.
Coluna Motivo excluída.
Coluna DataAbate excluída.
Coluna Data_homol excluída.
Coluna DataAbate_6m_ANT excluída.
Coluna data_homol_select excluída.
Coluna data12m excluída.
Coluna data6m excluída.
Coluna data3m excluída.
Coluna data1m excluída.
Coluna data7d excluída.
Coluna CATEGORIA excluída.
*****FIM DELETE COLUNAS*********

*****INICIO PRINT INFOS******
Número total de linhas do DataFrame: 63072
Número de colunas: 23
Informações do DataFrame:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 63072 entries, 0 to 63071
Data columns (total 23 columns):
 #   Column                            Non-Null Count  Dtype   
---  ------                            --------------  -----   
 0   ID_ANIMAL                         63072 non-null  uint32  
 1   Tipificacao                       63072 non-null  category
 2   Peso                              63072 non-null  float32 
 3   QuestionarioClassificacaoEstabel  63072 non-null  uint8   
 4   ILP                               63072 non-null  uint8   
 5   IFP                               63072 non-null  uint8   
 6   ILPF                              63072 non-null  uint8   
 7   QuestionarioPossuiOutrosIncentiv  63072 non-null  uint8   
 8   QuestionarioFabricaRacao          63072 non-null  uint8   
 9   regua de manejo                   63062 non-null  UInt8   
 10  identificacao individual          63062 non-null  UInt8   
 11  rastreamento SISBOV               63050 non-null  UInt8   
 12  participa de aliancas mercadolog  63062 non-null  UInt8   
 13  QuestionarioPraticaRecuperacaoPa  63072 non-null  uint8   
 14  Confinamento                      63062 non-null  UInt8   
 15  Suplementacao_a_campo             63062 non-null  UInt8   
 16  SemiConfinamento                  63062 non-null  UInt8   
 17  tot3m_Chuva                       61719 non-null  float32 
 18  med3m_formITUinst                 63063 non-null  float32 
 19  med3m_NDVI                        60906 non-null  float32 
 20  med3m_preR_milho                  63063 non-null  float32 
 21  med3m_preR_boi                    63063 non-null  float32 
 22  classificacao                     63072 non-null  category
dtypes: UInt8(7), category(2), float32(6), uint32(1), uint8(7)
memory usage: 3.1 MB
*****FIM PRINT INFOS*********
Function informations Took 0:00:00.013517

*****FIM LOAD DATA******
Function load_data Took 0:00:43.468515

*****INICIO SHOW SETTINGS******
os = <module 'os' from '/usr/lib/python3.8/os.py'>
pd = <module 'pandas' from '/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pandas/__init__.py'>
torch = <module 'torch' from '/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/torch/__init__.py'>
PANDAS_MAX_ROWS = 5000
random_seed = 42
n_jobs = 1
dataset_folder_path = /mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/base_dados/
csv_path = /mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/base_dados/TAB_MODELAGEM_RAFAEL_2020_1-2.0-percentage-sampling.csv
number_csv_lines = None
dtype_dict = {'ID_ANIMAL': 'uint32', 'EstabelecimentoMunicipio': 'category', 'Frigorifico_ID': 'uint8', 'Frigorifico_CNPJ': 'uint64', 'Frigorifico_RazaoSocial': 'category', 'Municipio_Frigorifico': 'category', 'Tipificacao': 'category', 'Maturidade': 'category', 'Acabamento': 'category', 'Peso': 'float32', 'EstabelecimentoIdentificador': 'uint16', 'Questionario_ID': 'uint16', 'QuestionarioClassificacaoEstabel': 'uint8', 'FERTIIRRIGACAO': 'uint8', 'ILP': 'uint8', 'IFP': 'uint8', 'ILPF': 'uint8', 'CONCEN_VOLUM': 'UInt8', 'CREEPFEEDING': 'UInt8', 'FORN_ESTRAT_SILAGEM': 'UInt8', 'PROTEICO': 'UInt8', 'PROTEICO_ENERGETICO': 'UInt8', 'RACAO_BAL_CONS_INFERIOR': 'UInt8', 'SAL_MINERAL': 'UInt8', 'SALMINERAL_UREIA': 'UInt8', 'RACAOO_BAL_CONSUMO_IG': 'UInt8', 'GRAO_INTEIRO': 'UInt8', 'ALTO_CONCENTR_VOLUM': 'UInt8', 'ALTO_CONCENTRADO': 'UInt8', 'QuestionarioPossuiOutrosIncentiv': 'uint8', 'QuestionarioFabricaRacao': 'uint8', 'area so confinamento': 'UInt8', 'regua de manejo': 'UInt8', 'boa cobertura vegetal, com baixa': 'UInt8', 'erosaoo laminar ou em sulco igua': 'UInt8', 'identificacao individual': 'UInt8', 'rastreamento SISBOV': 'UInt8', 'Lista Trace': 'UInt8', 'BPA': 'UInt8', 'participa de aliancas mercadolog': 'UInt8', 'QuestionarioPraticaRecuperacaoPa': 'uint8', 'Confinamento': 'UInt8', 'Suplementacao_a_campo': 'UInt8', 'SemiConfinamento': 'UInt8', 'dif_datas': 'uint16', 'tot7d_Chuva': 'float32', 'med7d_TempInst': 'float32', 'med7d_TempMin': 'float32', 'med7d_UmidInst': 'float32', 'med7d_formITUinst': 'float32', 'med7d_formITUmax': 'float32', 'med7d_NDVI': 'float32', 'med7d_EVI': 'float32', 'med7d_preR_soja': 'float32', 'med7d_preR_milho': 'float32', 'med7d_preR_boi': 'float32', 'tot1m_Chuva': 'float32', 'med1m_TempInst': 'float32', 'med1m_UmidInst': 'float32', 'med1m_formITUinst': 'float32', 'med1m_NDVI': 'float32', 'med1m_EVI': 'float32', 'med1m_preR_soja': 'float32', 'med1m_preR_milho': 'float32', 'med1m_preR_boi': 'float32', 'tot3m_Chuva': 'float32', 'med3m_TempInst': 'float32', 'med3m_UmidInst': 'float32', 'med3m_formITUinst': 'float32', 'med3m_formITUmax': 'float32', 'med3m_NDVI': 'float32', 'med3m_EVI': 'float32', 'med3m_preR_soja': 'float32', 'med3m_preR_milho': 'float32', 'med3m_preR_boi': 'float32', 'tot6m_Chuva': 'float32', 'med6m_TempInst': 'float32', 'med6m_UmidInst': 'float32', 'med6m_formITUinst': 'float32', 'med6m_NDVI': 'float32', 'med6m_EVI': 'float32', 'med6m_preR_soja': 'float32', 'med6m_preR_milho': 'float32', 'med6m_preR_boi': 'float32', 'tot12m_Chuva': 'float32', 'med12m_TempInst': 'float32', 'med12m_TempMin': 'float32', 'med12m_UmidInst': 'float32', 'med12m_formITUinst': 'float32', 'med12m_NDVI': 'float32', 'med12m_EVI': 'float32', 'med12m_preR_soja': 'float32', 'med12m_preR_milho': 'float32', 'med12m_preR_boi': 'float32', 'cnt7d_CL_ITUinst': 'float32', 'cnt1m_CL_ITUinst': 'float32', 'cnt3m_CL_ITUinst': 'float32', 'cnt6m_CL_ITUinst': 'float32', 'cnt12m_CL_ITUinst': 'float32', 'ANO': 'uint16', 'CATEGORIA': 'category', 'classificacao': 'category', 'Motivo': 'category', 'QTD_ANIMAIS_LOTE': 'uint16', 'PESO_MEDIO_LOTE': 'float32', 'CATEGORIA_BINARIA': 'category'}
parse_dates = ['DataAbate', 'Data_homol', 'DataAbate_6m_ANT', 'data_homol_select', 'data12m', 'data6m', 'data3m', 'data1m', 'data7d']
delete_columns_names_on_load_data = ['EstabelecimentoMunicipio', 'Frigorifico_ID', 'Frigorifico_CNPJ', 'Frigorifico_RazaoSocial', 'Municipio_Frigorifico', 'Maturidade', 'Acabamento', 'EstabelecimentoIdentificador', 'Questionario_ID', 'FERTIIRRIGACAO', 'CONCEN_VOLUM', 'CREEPFEEDING', 'FORN_ESTRAT_SILAGEM', 'PROTEICO', 'PROTEICO_ENERGETICO', 'RACAO_BAL_CONS_INFERIOR', 'SAL_MINERAL', 'SALMINERAL_UREIA', 'RACAOO_BAL_CONSUMO_IG', 'GRAO_INTEIRO', 'ALTO_CONCENTR_VOLUM', 'ALTO_CONCENTRADO', 'area so confinamento', 'boa cobertura vegetal, com baixa', 'erosaoo laminar ou em sulco igua', 'Lista Trace', 'BPA', 'dif_datas', 'tot7d_Chuva', 'med7d_TempInst', 'med7d_TempMin', 'med7d_UmidInst', 'med7d_formITUinst', 'med7d_formITUmax', 'med7d_NDVI', 'med7d_EVI', 'med7d_preR_soja', 'med7d_preR_milho', 'med7d_preR_boi', 'tot1m_Chuva', 'med1m_TempInst', 'med1m_UmidInst', 'med1m_formITUinst', 'med1m_NDVI', 'med1m_EVI', 'med1m_preR_soja', 'med1m_preR_milho', 'med1m_preR_boi', 'med3m_TempInst', 'med3m_UmidInst', 'med3m_formITUmax', 'med3m_EVI', 'med3m_preR_soja', 'tot6m_Chuva', 'med6m_TempInst', 'med6m_UmidInst', 'med6m_formITUinst', 'med6m_NDVI', 'med6m_EVI', 'med6m_preR_soja', 'med6m_preR_milho', 'med6m_preR_boi', 'tot12m_Chuva', 'med12m_TempInst', 'med12m_TempMin', 'med12m_UmidInst', 'med12m_formITUinst', 'med12m_NDVI', 'med12m_EVI', 'med12m_preR_soja', 'med12m_preR_milho', 'med12m_preR_boi', 'cnt7d_CL_ITUinst', 'cnt1m_CL_ITUinst', 'cnt3m_CL_ITUinst', 'cnt6m_CL_ITUinst', 'cnt12m_CL_ITUinst', 'ANO', 'Motivo', 'DataAbate', 'Data_homol', 'DataAbate_6m_ANT', 'data_homol_select', 'data12m', 'data6m', 'data3m', 'data1m', 'data7d', 'CATEGORIA']
PATH_SAVE_PLOTS = ./plots
PATH_SAVE_ESTIMATORS_REPR = ./runs/estimators_repr
PATH_SAVE_BEST_ESTIMATORS = ./runs/best_estimators
PATH_SAVE_RESULTS = ./runs/results
PATH_SAVE_LOGS = ./logs
PATH_SAVE_ENCODERS_SCALERS = ./runs/encoders_scalers
ordinal_encoder_columns_names = {'QuestionarioClassificacaoEstabel': ['0', '21', '26', '30']}
columns_ordinal_encoded = {}
label_encoder_columns_names = ['classificacao']
columns_label_encoded = {}
one_hot_encoder_columns_names = ['Tipificacao']
columns_one_hot_encoded = {}
min_max_scaler_columns_names = ['Peso', 'tot3m_Chuva', 'med3m_formITUinst', 'med3m_NDVI', 'med3m_preR_milho', 'med3m_preR_boi']
columns_min_max_scaled = {}
columns_label_binarized = {}
simple_imputer_columns_names = []
columns_names_drop_feature_by_correlation = ['med3m_formITUinst', 'med3m_preR_boi', 'classificacao']
class_column = classificacao
classifiers = {}
models_results = {}
device_name = cpu
use_embeddings = True
use_cat_emb_dim = True
threshold_categorical_features = 150
num_workers = 4
eval_metric = ['balanced_accuracy', 'logloss', <class 'pytorch_tabnet_tuner.tab_model_tuner.F1ScoreMacro'>]
augmentations = None
weights = 0
batch_size = 1024
virtual_batch_size = 128
run_grid_search_cv_tuner = True
save_results_during_run = True
new_run = True
PATH_OBJECTS_PERSISTED_RESULTS_RUNS = ./runs/objects_persisted_results_runs
PARAMETERS_PERSIST_FILENAME = ./runs/objects_persisted_results_runs/parameters_persist
RESULTS_PERSIST_FILENAME = ./runs/objects_persisted_results_runs/results_persist
SPLIT_PERSIST_FILENAME = ./runs/objects_persisted_results_runs/split_persist
tree_method = hist
objective = binary:logistic
*****FIM SHOW SETTINGS******


*****INICIO DELETE DUPLICATE ROWS BY ATTRIBUTE******
Nenhuma linha duplicada encontrada para o atributo ID_ANIMAL.
*****FIM DELETE DUPLICATE ROWS BY ATTRIBUTE*********
Function delete_duplicate_rows_by_attribute Took 0:00:00.038519

*****INICIO DELETE COLUNAS******
Coluna ID_ANIMAL excluída.
*****FIM DELETE COLUNAS*********

*****INICIO DELETE NAN ROWS******
Linhas com valores NaN encontradas.
*****FIM DELETE NAN ROWS*********
Function delete_nan_rows Took 0:00:00.048166


*****INICIO DELETE COLUMNS WITH SINGLE VALUE******
>>> Nenhuma coluna com valor único encontrada.
*****FIM DELETE COLUMNS WITH SINGLE VALUE*********
Function delete_columns_with_single_value Took 0:00:00.029194


*****INICIO LABEL ENCODER******
*****FIM LABEL ENCODER*********
Function label_encoder_columns Took 0:00:00.024885

Object saved in file: ./runs/encoders_scalers/target_encoded-15-04-2023_09:04:08.joblib

*****INICIO RELATÓRIO DISTRIBUIÇÃO DE CLASSES******
Distribuição da classe 1: 83%
Distribuição da classe 0: 17%
Erro majoritário: 17%
*****FIM RELATÓRIO DISTRIBUIÇÃO DE CLASSES******
Function class_distribution Took 0:00:00.007708

/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu
  warnings.warn(f"Device used : {self.device}")
Number of folds for cross validation: 5
Scoring strategy for grid search: f1_macro
Test Size: 0.2

x_train shape: (47635, 21)
y_train shape: (47635,)
x_test shape: (11909, 21)
y_test shape: (11909,)
Removing all files in directory: ./runs/objects_persisted_results_runs
Do you want to continue? (y/n): 
All files in directory ./runs/objects_persisted_results_runs were removed.
Fitting 5 folds for each of 7 candidates, totalling 35 fits
[CV 1/5; 1/7] START classifier__estimator=GaussianNB()..........................
[CV 1/5; 1/7] END classifier__estimator=GaussianNB();, score=0.496 total time=   2.6s
[CV 2/5; 1/7] START classifier__estimator=GaussianNB()..........................
[CV 2/5; 1/7] END classifier__estimator=GaussianNB();, score=0.497 total time=   0.6s
[CV 3/5; 1/7] START classifier__estimator=GaussianNB()..........................
[CV 3/5; 1/7] END classifier__estimator=GaussianNB();, score=0.500 total time=   0.7s
[CV 4/5; 1/7] START classifier__estimator=GaussianNB()..........................
[CV 4/5; 1/7] END classifier__estimator=GaussianNB();, score=0.497 total time=   0.9s
[CV 5/5; 1/7] START classifier__estimator=GaussianNB()..........................
[CV 5/5; 1/7] END classifier__estimator=GaussianNB();, score=0.482 total time=   0.7s
[CV 1/5; 2/7] START classifier__estimator=DecisionTreeClassifier(), classifier__estimator__class_weight=None, classifier__estimator__criterion=gini, classifier__estimator__max_depth=None, classifier__estimator__min_samples_leaf=10, classifier__estimator__min_samples_split=100, classifier__estimator__random_state=42, classifier__estimator__splitter=best
[CV 1/5; 2/7] END classifier__estimator=DecisionTreeClassifier(), classifier__estimator__class_weight=None, classifier__estimator__criterion=gini, classifier__estimator__max_depth=None, classifier__estimator__min_samples_leaf=10, classifier__estimator__min_samples_split=100, classifier__estimator__random_state=42, classifier__estimator__splitter=best;, score=0.610 total time=   0.8s
[CV 2/5; 2/7] START classifier__estimator=DecisionTreeClassifier(), classifier__estimator__class_weight=None, classifier__estimator__criterion=gini, classifier__estimator__max_depth=None, classifier__estimator__min_samples_leaf=10, classifier__estimator__min_samples_split=100, classifier__estimator__random_state=42, classifier__estimator__splitter=best
[CV 2/5; 2/7] END classifier__estimator=DecisionTreeClassifier(), classifier__estimator__class_weight=None, classifier__estimator__criterion=gini, classifier__estimator__max_depth=None, classifier__estimator__min_samples_leaf=10, classifier__estimator__min_samples_split=100, classifier__estimator__random_state=42, classifier__estimator__splitter=best;, score=0.609 total time=   0.8s
[CV 3/5; 2/7] START classifier__estimator=DecisionTreeClassifier(), classifier__estimator__class_weight=None, classifier__estimator__criterion=gini, classifier__estimator__max_depth=None, classifier__estimator__min_samples_leaf=10, classifier__estimator__min_samples_split=100, classifier__estimator__random_state=42, classifier__estimator__splitter=best
[CV 3/5; 2/7] END classifier__estimator=DecisionTreeClassifier(), classifier__estimator__class_weight=None, classifier__estimator__criterion=gini, classifier__estimator__max_depth=None, classifier__estimator__min_samples_leaf=10, classifier__estimator__min_samples_split=100, classifier__estimator__random_state=42, classifier__estimator__splitter=best;, score=0.602 total time=   0.9s
[CV 4/5; 2/7] START classifier__estimator=DecisionTreeClassifier(), classifier__estimator__class_weight=None, classifier__estimator__criterion=gini, classifier__estimator__max_depth=None, classifier__estimator__min_samples_leaf=10, classifier__estimator__min_samples_split=100, classifier__estimator__random_state=42, classifier__estimator__splitter=best
[CV 4/5; 2/7] END classifier__estimator=DecisionTreeClassifier(), classifier__estimator__class_weight=None, classifier__estimator__criterion=gini, classifier__estimator__max_depth=None, classifier__estimator__min_samples_leaf=10, classifier__estimator__min_samples_split=100, classifier__estimator__random_state=42, classifier__estimator__splitter=best;, score=0.589 total time=   0.8s
[CV 5/5; 2/7] START classifier__estimator=DecisionTreeClassifier(), classifier__estimator__class_weight=None, classifier__estimator__criterion=gini, classifier__estimator__max_depth=None, classifier__estimator__min_samples_leaf=10, classifier__estimator__min_samples_split=100, classifier__estimator__random_state=42, classifier__estimator__splitter=best
[CV 5/5; 2/7] END classifier__estimator=DecisionTreeClassifier(), classifier__estimator__class_weight=None, classifier__estimator__criterion=gini, classifier__estimator__max_depth=None, classifier__estimator__min_samples_leaf=10, classifier__estimator__min_samples_split=100, classifier__estimator__random_state=42, classifier__estimator__splitter=best;, score=0.605 total time=   0.8s
[CV 1/5; 3/7] START classifier__estimator=LinearSVC(), classifier__estimator__C=0.001, classifier__estimator__class_weight=None, classifier__estimator__dual=False, classifier__estimator__max_iter=10000, classifier__estimator__penalty=l2, classifier__estimator__random_state=42
[CV 1/5; 3/7] END classifier__estimator=LinearSVC(), classifier__estimator__C=0.001, classifier__estimator__class_weight=None, classifier__estimator__dual=False, classifier__estimator__max_iter=10000, classifier__estimator__penalty=l2, classifier__estimator__random_state=42;, score=0.554 total time=   0.7s
[CV 2/5; 3/7] START classifier__estimator=LinearSVC(), classifier__estimator__C=0.001, classifier__estimator__class_weight=None, classifier__estimator__dual=False, classifier__estimator__max_iter=10000, classifier__estimator__penalty=l2, classifier__estimator__random_state=42
[CV 2/5; 3/7] END classifier__estimator=LinearSVC(), classifier__estimator__C=0.001, classifier__estimator__class_weight=None, classifier__estimator__dual=False, classifier__estimator__max_iter=10000, classifier__estimator__penalty=l2, classifier__estimator__random_state=42;, score=0.550 total time=   0.7s
[CV 3/5; 3/7] START classifier__estimator=LinearSVC(), classifier__estimator__C=0.001, classifier__estimator__class_weight=None, classifier__estimator__dual=False, classifier__estimator__max_iter=10000, classifier__estimator__penalty=l2, classifier__estimator__random_state=42
[CV 3/5; 3/7] END classifier__estimator=LinearSVC(), classifier__estimator__C=0.001, classifier__estimator__class_weight=None, classifier__estimator__dual=False, classifier__estimator__max_iter=10000, classifier__estimator__penalty=l2, classifier__estimator__random_state=42;, score=0.546 total time=   0.7s
[CV 4/5; 3/7] START classifier__estimator=LinearSVC(), classifier__estimator__C=0.001, classifier__estimator__class_weight=None, classifier__estimator__dual=False, classifier__estimator__max_iter=10000, classifier__estimator__penalty=l2, classifier__estimator__random_state=42
[CV 4/5; 3/7] END classifier__estimator=LinearSVC(), classifier__estimator__C=0.001, classifier__estimator__class_weight=None, classifier__estimator__dual=False, classifier__estimator__max_iter=10000, classifier__estimator__penalty=l2, classifier__estimator__random_state=42;, score=0.546 total time=   0.7s
[CV 5/5; 3/7] START classifier__estimator=LinearSVC(), classifier__estimator__C=0.001, classifier__estimator__class_weight=None, classifier__estimator__dual=False, classifier__estimator__max_iter=10000, classifier__estimator__penalty=l2, classifier__estimator__random_state=42
[CV 5/5; 3/7] END classifier__estimator=LinearSVC(), classifier__estimator__C=0.001, classifier__estimator__class_weight=None, classifier__estimator__dual=False, classifier__estimator__max_iter=10000, classifier__estimator__penalty=l2, classifier__estimator__random_state=42;, score=0.549 total time=   0.7s
[CV 1/5; 4/7] START classifier__estimator=MLPClassifier(), classifier__estimator__activation=relu, classifier__estimator__alpha=0.0001, classifier__estimator__early_stopping=True, classifier__estimator__hidden_layer_sizes=(50, 100, 50), classifier__estimator__learning_rate=adaptive, classifier__estimator__learning_rate_init=0.0001, classifier__estimator__max_iter=1000, classifier__estimator__momentum=0.0, classifier__estimator__random_state=42, classifier__estimator__solver=adam
[CV 1/5; 4/7] END classifier__estimator=MLPClassifier(), classifier__estimator__activation=relu, classifier__estimator__alpha=0.0001, classifier__estimator__early_stopping=True, classifier__estimator__hidden_layer_sizes=(50, 100, 50), classifier__estimator__learning_rate=adaptive, classifier__estimator__learning_rate_init=0.0001, classifier__estimator__max_iter=1000, classifier__estimator__momentum=0.0, classifier__estimator__random_state=42, classifier__estimator__solver=adam;, score=0.581 total time=  52.2s
[CV 2/5; 4/7] START classifier__estimator=MLPClassifier(), classifier__estimator__activation=relu, classifier__estimator__alpha=0.0001, classifier__estimator__early_stopping=True, classifier__estimator__hidden_layer_sizes=(50, 100, 50), classifier__estimator__learning_rate=adaptive, classifier__estimator__learning_rate_init=0.0001, classifier__estimator__max_iter=1000, classifier__estimator__momentum=0.0, classifier__estimator__random_state=42, classifier__estimator__solver=adam
[CV 2/5; 4/7] END classifier__estimator=MLPClassifier(), classifier__estimator__activation=relu, classifier__estimator__alpha=0.0001, classifier__estimator__early_stopping=True, classifier__estimator__hidden_layer_sizes=(50, 100, 50), classifier__estimator__learning_rate=adaptive, classifier__estimator__learning_rate_init=0.0001, classifier__estimator__max_iter=1000, classifier__estimator__momentum=0.0, classifier__estimator__random_state=42, classifier__estimator__solver=adam;, score=0.556 total time=  14.4s
[CV 3/5; 4/7] START classifier__estimator=MLPClassifier(), classifier__estimator__activation=relu, classifier__estimator__alpha=0.0001, classifier__estimator__early_stopping=True, classifier__estimator__hidden_layer_sizes=(50, 100, 50), classifier__estimator__learning_rate=adaptive, classifier__estimator__learning_rate_init=0.0001, classifier__estimator__max_iter=1000, classifier__estimator__momentum=0.0, classifier__estimator__random_state=42, classifier__estimator__solver=adam
[CV 3/5; 4/7] END classifier__estimator=MLPClassifier(), classifier__estimator__activation=relu, classifier__estimator__alpha=0.0001, classifier__estimator__early_stopping=True, classifier__estimator__hidden_layer_sizes=(50, 100, 50), classifier__estimator__learning_rate=adaptive, classifier__estimator__learning_rate_init=0.0001, classifier__estimator__max_iter=1000, classifier__estimator__momentum=0.0, classifier__estimator__random_state=42, classifier__estimator__solver=adam;, score=0.578 total time=  31.1s
[CV 4/5; 4/7] START classifier__estimator=MLPClassifier(), classifier__estimator__activation=relu, classifier__estimator__alpha=0.0001, classifier__estimator__early_stopping=True, classifier__estimator__hidden_layer_sizes=(50, 100, 50), classifier__estimator__learning_rate=adaptive, classifier__estimator__learning_rate_init=0.0001, classifier__estimator__max_iter=1000, classifier__estimator__momentum=0.0, classifier__estimator__random_state=42, classifier__estimator__solver=adam
[CV 4/5; 4/7] END classifier__estimator=MLPClassifier(), classifier__estimator__activation=relu, classifier__estimator__alpha=0.0001, classifier__estimator__early_stopping=True, classifier__estimator__hidden_layer_sizes=(50, 100, 50), classifier__estimator__learning_rate=adaptive, classifier__estimator__learning_rate_init=0.0001, classifier__estimator__max_iter=1000, classifier__estimator__momentum=0.0, classifier__estimator__random_state=42, classifier__estimator__solver=adam;, score=0.556 total time=  11.4s
[CV 5/5; 4/7] START classifier__estimator=MLPClassifier(), classifier__estimator__activation=relu, classifier__estimator__alpha=0.0001, classifier__estimator__early_stopping=True, classifier__estimator__hidden_layer_sizes=(50, 100, 50), classifier__estimator__learning_rate=adaptive, classifier__estimator__learning_rate_init=0.0001, classifier__estimator__max_iter=1000, classifier__estimator__momentum=0.0, classifier__estimator__random_state=42, classifier__estimator__solver=adam
[CV 5/5; 4/7] END classifier__estimator=MLPClassifier(), classifier__estimator__activation=relu, classifier__estimator__alpha=0.0001, classifier__estimator__early_stopping=True, classifier__estimator__hidden_layer_sizes=(50, 100, 50), classifier__estimator__learning_rate=adaptive, classifier__estimator__learning_rate_init=0.0001, classifier__estimator__max_iter=1000, classifier__estimator__momentum=0.0, classifier__estimator__random_state=42, classifier__estimator__solver=adam;, score=0.573 total time=  29.0s
[CV 1/5; 5/7] START classifier__estimator=RandomForestClassifier(), classifier__estimator__class_weight=None, classifier__estimator__criterion=entropy, classifier__estimator__max_depth=None, classifier__estimator__max_features=0.75, classifier__estimator__n_estimators=1000, classifier__estimator__n_jobs=-1, classifier__estimator__random_state=42
[CV 1/5; 5/7] END classifier__estimator=RandomForestClassifier(), classifier__estimator__class_weight=None, classifier__estimator__criterion=entropy, classifier__estimator__max_depth=None, classifier__estimator__max_features=0.75, classifier__estimator__n_estimators=1000, classifier__estimator__n_jobs=-1, classifier__estimator__random_state=42;, score=0.662 total time= 1.3min
[CV 2/5; 5/7] START classifier__estimator=RandomForestClassifier(), classifier__estimator__class_weight=None, classifier__estimator__criterion=entropy, classifier__estimator__max_depth=None, classifier__estimator__max_features=0.75, classifier__estimator__n_estimators=1000, classifier__estimator__n_jobs=-1, classifier__estimator__random_state=42
[CV 2/5; 5/7] END classifier__estimator=RandomForestClassifier(), classifier__estimator__class_weight=None, classifier__estimator__criterion=entropy, classifier__estimator__max_depth=None, classifier__estimator__max_features=0.75, classifier__estimator__n_estimators=1000, classifier__estimator__n_jobs=-1, classifier__estimator__random_state=42;, score=0.670 total time= 1.2min
[CV 3/5; 5/7] START classifier__estimator=RandomForestClassifier(), classifier__estimator__class_weight=None, classifier__estimator__criterion=entropy, classifier__estimator__max_depth=None, classifier__estimator__max_features=0.75, classifier__estimator__n_estimators=1000, classifier__estimator__n_jobs=-1, classifier__estimator__random_state=42
[CV 3/5; 5/7] END classifier__estimator=RandomForestClassifier(), classifier__estimator__class_weight=None, classifier__estimator__criterion=entropy, classifier__estimator__max_depth=None, classifier__estimator__max_features=0.75, classifier__estimator__n_estimators=1000, classifier__estimator__n_jobs=-1, classifier__estimator__random_state=42;, score=0.661 total time= 1.2min
[CV 4/5; 5/7] START classifier__estimator=RandomForestClassifier(), classifier__estimator__class_weight=None, classifier__estimator__criterion=entropy, classifier__estimator__max_depth=None, classifier__estimator__max_features=0.75, classifier__estimator__n_estimators=1000, classifier__estimator__n_jobs=-1, classifier__estimator__random_state=42
[CV 4/5; 5/7] END classifier__estimator=RandomForestClassifier(), classifier__estimator__class_weight=None, classifier__estimator__criterion=entropy, classifier__estimator__max_depth=None, classifier__estimator__max_features=0.75, classifier__estimator__n_estimators=1000, classifier__estimator__n_jobs=-1, classifier__estimator__random_state=42;, score=0.664 total time= 1.2min
[CV 5/5; 5/7] START classifier__estimator=RandomForestClassifier(), classifier__estimator__class_weight=None, classifier__estimator__criterion=entropy, classifier__estimator__max_depth=None, classifier__estimator__max_features=0.75, classifier__estimator__n_estimators=1000, classifier__estimator__n_jobs=-1, classifier__estimator__random_state=42
[CV 5/5; 5/7] END classifier__estimator=RandomForestClassifier(), classifier__estimator__class_weight=None, classifier__estimator__criterion=entropy, classifier__estimator__max_depth=None, classifier__estimator__max_features=0.75, classifier__estimator__n_estimators=1000, classifier__estimator__n_jobs=-1, classifier__estimator__random_state=42;, score=0.668 total time= 1.3min
[CV 1/5; 6/7] START classifier__estimator=XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=None,
              num_parallel_tree=None, predictor=None, random_state=None,
              reg_alpha=None, reg_lambda=None, ...), classifier__estimator__colsample_bytree=0.75, classifier__estimator__gamma=0.05, classifier__estimator__learning_rate=0.01, classifier__estimator__max_delta_step=1.0, classifier__estimator__max_depth=None, classifier__estimator__n_estimators=1000, classifier__estimator__n_jobs=-1, classifier__estimator__objective=binary:logistic, classifier__estimator__random_state=42, classifier__estimator__reg_alpha=0, classifier__estimator__reg_lambda=0.01, classifier__estimator__subsample=0.75, classifier__estimator__tree_method=hist
[CV 1/5; 6/7] END classifier__estimator=XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=None,
              num_parallel_tree=None, predictor=None, random_state=None,
              reg_alpha=None, reg_lambda=None, ...), classifier__estimator__colsample_bytree=0.75, classifier__estimator__gamma=0.05, classifier__estimator__learning_rate=0.01, classifier__estimator__max_delta_step=1.0, classifier__estimator__max_depth=None, classifier__estimator__n_estimators=1000, classifier__estimator__n_jobs=-1, classifier__estimator__objective=binary:logistic, classifier__estimator__random_state=42, classifier__estimator__reg_alpha=0, classifier__estimator__reg_lambda=0.01, classifier__estimator__subsample=0.75, classifier__estimator__tree_method=hist;, score=0.645 total time=   4.9s
[CV 2/5; 6/7] START classifier__estimator=XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=None,
              num_parallel_tree=None, predictor=None, random_state=None,
              reg_alpha=None, reg_lambda=None, ...), classifier__estimator__colsample_bytree=0.75, classifier__estimator__gamma=0.05, classifier__estimator__learning_rate=0.01, classifier__estimator__max_delta_step=1.0, classifier__estimator__max_depth=None, classifier__estimator__n_estimators=1000, classifier__estimator__n_jobs=-1, classifier__estimator__objective=binary:logistic, classifier__estimator__random_state=42, classifier__estimator__reg_alpha=0, classifier__estimator__reg_lambda=0.01, classifier__estimator__subsample=0.75, classifier__estimator__tree_method=hist
[CV 2/5; 6/7] END classifier__estimator=XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=None,
              num_parallel_tree=None, predictor=None, random_state=None,
              reg_alpha=None, reg_lambda=None, ...), classifier__estimator__colsample_bytree=0.75, classifier__estimator__gamma=0.05, classifier__estimator__learning_rate=0.01, classifier__estimator__max_delta_step=1.0, classifier__estimator__max_depth=None, classifier__estimator__n_estimators=1000, classifier__estimator__n_jobs=-1, classifier__estimator__objective=binary:logistic, classifier__estimator__random_state=42, classifier__estimator__reg_alpha=0, classifier__estimator__reg_lambda=0.01, classifier__estimator__subsample=0.75, classifier__estimator__tree_method=hist;, score=0.661 total time=   5.7s
[CV 3/5; 6/7] START classifier__estimator=XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=None,
              num_parallel_tree=None, predictor=None, random_state=None,
              reg_alpha=None, reg_lambda=None, ...), classifier__estimator__colsample_bytree=0.75, classifier__estimator__gamma=0.05, classifier__estimator__learning_rate=0.01, classifier__estimator__max_delta_step=1.0, classifier__estimator__max_depth=None, classifier__estimator__n_estimators=1000, classifier__estimator__n_jobs=-1, classifier__estimator__objective=binary:logistic, classifier__estimator__random_state=42, classifier__estimator__reg_alpha=0, classifier__estimator__reg_lambda=0.01, classifier__estimator__subsample=0.75, classifier__estimator__tree_method=hist
[CV 3/5; 6/7] END classifier__estimator=XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=None,
              num_parallel_tree=None, predictor=None, random_state=None,
              reg_alpha=None, reg_lambda=None, ...), classifier__estimator__colsample_bytree=0.75, classifier__estimator__gamma=0.05, classifier__estimator__learning_rate=0.01, classifier__estimator__max_delta_step=1.0, classifier__estimator__max_depth=None, classifier__estimator__n_estimators=1000, classifier__estimator__n_jobs=-1, classifier__estimator__objective=binary:logistic, classifier__estimator__random_state=42, classifier__estimator__reg_alpha=0, classifier__estimator__reg_lambda=0.01, classifier__estimator__subsample=0.75, classifier__estimator__tree_method=hist;, score=0.645 total time=   5.0s
[CV 4/5; 6/7] START classifier__estimator=XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=None,
              num_parallel_tree=None, predictor=None, random_state=None,
              reg_alpha=None, reg_lambda=None, ...), classifier__estimator__colsample_bytree=0.75, classifier__estimator__gamma=0.05, classifier__estimator__learning_rate=0.01, classifier__estimator__max_delta_step=1.0, classifier__estimator__max_depth=None, classifier__estimator__n_estimators=1000, classifier__estimator__n_jobs=-1, classifier__estimator__objective=binary:logistic, classifier__estimator__random_state=42, classifier__estimator__reg_alpha=0, classifier__estimator__reg_lambda=0.01, classifier__estimator__subsample=0.75, classifier__estimator__tree_method=hist
[CV 4/5; 6/7] END classifier__estimator=XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=None,
              num_parallel_tree=None, predictor=None, random_state=None,
              reg_alpha=None, reg_lambda=None, ...), classifier__estimator__colsample_bytree=0.75, classifier__estimator__gamma=0.05, classifier__estimator__learning_rate=0.01, classifier__estimator__max_delta_step=1.0, classifier__estimator__max_depth=None, classifier__estimator__n_estimators=1000, classifier__estimator__n_jobs=-1, classifier__estimator__objective=binary:logistic, classifier__estimator__random_state=42, classifier__estimator__reg_alpha=0, classifier__estimator__reg_lambda=0.01, classifier__estimator__subsample=0.75, classifier__estimator__tree_method=hist;, score=0.646 total time=   5.1s
[CV 5/5; 6/7] START classifier__estimator=XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=None,
              num_parallel_tree=None, predictor=None, random_state=None,
              reg_alpha=None, reg_lambda=None, ...), classifier__estimator__colsample_bytree=0.75, classifier__estimator__gamma=0.05, classifier__estimator__learning_rate=0.01, classifier__estimator__max_delta_step=1.0, classifier__estimator__max_depth=None, classifier__estimator__n_estimators=1000, classifier__estimator__n_jobs=-1, classifier__estimator__objective=binary:logistic, classifier__estimator__random_state=42, classifier__estimator__reg_alpha=0, classifier__estimator__reg_lambda=0.01, classifier__estimator__subsample=0.75, classifier__estimator__tree_method=hist
[CV 5/5; 6/7] END classifier__estimator=XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=None,
              num_parallel_tree=None, predictor=None, random_state=None,
              reg_alpha=None, reg_lambda=None, ...), classifier__estimator__colsample_bytree=0.75, classifier__estimator__gamma=0.05, classifier__estimator__learning_rate=0.01, classifier__estimator__max_delta_step=1.0, classifier__estimator__max_depth=None, classifier__estimator__n_estimators=1000, classifier__estimator__n_jobs=-1, classifier__estimator__objective=binary:logistic, classifier__estimator__random_state=42, classifier__estimator__reg_alpha=0, classifier__estimator__reg_lambda=0.01, classifier__estimator__subsample=0.75, classifier__estimator__tree_method=hist;, score=0.657 total time=   5.0s
[CV 1/5; 7/7] START classifier__estimator=TabNetClassifierTuner(n_d=8, n_a=8, n_steps=3, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=1, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=None, output_dim=None, device_name='cpu', n_shared_decoder=1, n_indep_decoder=1, use_embeddings=True, threshold_categorical_features=150, use_cat_emb_dim=True, fit_eval_metric=['balanced_accuracy', 'logloss', <class 'pytorch_tabnet_tuner.tab_model_tuner.F1ScoreMacro'>], fit_weights=0, fit_batch_size=1024, fit_virtual_batch_size=128), classifier__estimator__cat_emb_dim=20, classifier__estimator__clip_value=1, classifier__estimator__gamma=2.0, classifier__estimator__lambda_sparse=0.001, classifier__estimator__mask_type=sparsemax, classifier__estimator__momentum=0.4, classifier__estimator__n_a=64, classifier__estimator__n_independent=5, classifier__estimator__n_shared=5, classifier__estimator__n_steps=10, classifier__estimator__optimizer_fn=<class 'torch.optim.adam.Adam'>, classifier__estimator__optimizer_params={'lr': 0.02}, classifier__estimator__scheduler_fn=<class 'torch.optim.lr_scheduler.StepLR'>, classifier__estimator__scheduler_params={'step_size': 10, 'gamma': 0.95}, classifier__estimator__seed=42, classifier__estimator__verbose=1
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu
  warnings.warn(f"Device used : {self.device}")
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: n_d changed from 8 to 64
  warnings.warn(wrn_msg)
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: cat_dims changed from [] to [35, 2, 5, 5, 9, 11, 4, 17, 28, 23, 9, 21, 20, 18, 37, 26, 16]
  warnings.warn(wrn_msg)
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: cat_emb_dim changed from 20 to [17, 1, 2, 2, 4, 5, 2, 8, 14, 11, 4, 10, 10, 9, 18, 13, 8]
  warnings.warn(wrn_msg)
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: cat_idxs changed from [] to [0, 1, 2, 3, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]
  warnings.warn(wrn_msg)
epoch 0  | loss: 2.12869 | train_balanced_accuracy: 0.49909 | train_logloss: 2.01557 | train_f1_macro: 0.38021 | valid_balanced_accuracy: 0.49716 | valid_logloss: 2.03348 | valid_f1_macro: 0.37781 |  0:00:25s
epoch 1  | loss: 1.61703 | train_balanced_accuracy: 0.50791 | train_logloss: 1.11627 | train_f1_macro: 0.48407 | valid_balanced_accuracy: 0.50486 | valid_logloss: 1.1285  | valid_f1_macro: 0.48011 |  0:00:49s
epoch 2  | loss: 2.47825 | train_balanced_accuracy: 0.507   | train_logloss: 1.00628 | train_f1_macro: 0.43513 | valid_balanced_accuracy: 0.50028 | valid_logloss: 1.02391 | valid_f1_macro: 0.42818 |  0:01:16s
epoch 3  | loss: 1.76205 | train_balanced_accuracy: 0.49201 | train_logloss: 1.06227 | train_f1_macro: 0.38714 | valid_balanced_accuracy: 0.49636 | valid_logloss: 1.05796 | valid_f1_macro: 0.3872  |  0:01:41s
epoch 4  | loss: 1.85485 | train_balanced_accuracy: 0.49923 | train_logloss: 2.13307 | train_f1_macro: 0.37033 | valid_balanced_accuracy: 0.49823 | valid_logloss: 2.13637 | valid_f1_macro: 0.37003 |  0:02:06s
epoch 5  | loss: 1.21826 | train_balanced_accuracy: 0.49985 | train_logloss: 0.78142 | train_f1_macro: 0.37131 | valid_balanced_accuracy: 0.50042 | valid_logloss: 0.77804 | valid_f1_macro: 0.37196 |  0:02:29s
epoch 6  | loss: 0.74932 | train_balanced_accuracy: 0.535   | train_logloss: 0.72797 | train_f1_macro: 0.49153 | valid_balanced_accuracy: 0.5395  | valid_logloss: 0.72517 | valid_f1_macro: 0.4979  |  0:02:52s
epoch 7  | loss: 0.6979  | train_balanced_accuracy: 0.49987 | train_logloss: 0.67558 | train_f1_macro: 0.37244 | valid_balanced_accuracy: 0.50074 | valid_logloss: 0.67384 | valid_f1_macro: 0.37391 |  0:03:14s
epoch 8  | loss: 0.67309 | train_balanced_accuracy: 0.50715 | train_logloss: 0.67291 | train_f1_macro: 0.4011  | valid_balanced_accuracy: 0.50019 | valid_logloss: 0.67476 | valid_f1_macro: 0.39121 |  0:03:37s
epoch 9  | loss: 0.66955 | train_balanced_accuracy: 0.50186 | train_logloss: 0.67211 | train_f1_macro: 0.38361 | valid_balanced_accuracy: 0.49982 | valid_logloss: 0.67309 | valid_f1_macro: 0.37957 |  0:04:00s
epoch 10 | loss: 0.67053 | train_balanced_accuracy: 0.5132  | train_logloss: 0.67533 | train_f1_macro: 0.44036 | valid_balanced_accuracy: 0.50895 | valid_logloss: 0.67766 | valid_f1_macro: 0.43675 |  0:04:24s
epoch 11 | loss: 0.67213 | train_balanced_accuracy: 0.51857 | train_logloss: 0.67774 | train_f1_macro: 0.44459 | valid_balanced_accuracy: 0.51872 | valid_logloss: 0.67685 | valid_f1_macro: 0.44738 |  0:04:48s
epoch 12 | loss: 0.67272 | train_balanced_accuracy: 0.50372 | train_logloss: 0.67279 | train_f1_macro: 0.40909 | valid_balanced_accuracy: 0.50262 | valid_logloss: 0.67253 | valid_f1_macro: 0.40744 |  0:05:12s
epoch 13 | loss: 0.67274 | train_balanced_accuracy: 0.49963 | train_logloss: 0.67387 | train_f1_macro: 0.37564 | valid_balanced_accuracy: 0.5     | valid_logloss: 0.6736  | valid_f1_macro: 0.37664 |  0:05:38s
epoch 14 | loss: 0.67136 | train_balanced_accuracy: 0.49995 | train_logloss: 0.67333 | train_f1_macro: 0.37678 | valid_balanced_accuracy: 0.50227 | valid_logloss: 0.67317 | valid_f1_macro: 0.37906 |  0:06:25s
epoch 15 | loss: 0.67076 | train_balanced_accuracy: 0.52924 | train_logloss: 0.67396 | train_f1_macro: 0.49362 | valid_balanced_accuracy: 0.52889 | valid_logloss: 0.67437 | valid_f1_macro: 0.49381 |  0:06:53s
epoch 16 | loss: 0.6701  | train_balanced_accuracy: 0.50104 | train_logloss: 0.67073 | train_f1_macro: 0.37699 | valid_balanced_accuracy: 0.49871 | valid_logloss: 0.67081 | valid_f1_macro: 0.37294 |  0:07:15s
epoch 17 | loss: 0.67221 | train_balanced_accuracy: 0.51532 | train_logloss: 0.68217 | train_f1_macro: 0.43837 | valid_balanced_accuracy: 0.51772 | valid_logloss: 0.68401 | valid_f1_macro: 0.44442 |  0:07:37s
epoch 18 | loss: 0.67204 | train_balanced_accuracy: 0.51474 | train_logloss: 0.67105 | train_f1_macro: 0.43857 | valid_balanced_accuracy: 0.52025 | valid_logloss: 0.67179 | valid_f1_macro: 0.4473  |  0:07:58s
epoch 19 | loss: 0.6717  | train_balanced_accuracy: 0.50898 | train_logloss: 0.67721 | train_f1_macro: 0.405   | valid_balanced_accuracy: 0.5058  | valid_logloss: 0.68018 | valid_f1_macro: 0.40012 |  0:08:20s
epoch 20 | loss: 0.66908 | train_balanced_accuracy: 0.50361 | train_logloss: 0.6722  | train_f1_macro: 0.39605 | valid_balanced_accuracy: 0.50011 | valid_logloss: 0.67563 | valid_f1_macro: 0.39078 |  0:08:41s
epoch 21 | loss: 0.66983 | train_balanced_accuracy: 0.52977 | train_logloss: 0.6693  | train_f1_macro: 0.49163 | valid_balanced_accuracy: 0.51895 | valid_logloss: 0.67348 | valid_f1_macro: 0.47662 |  0:09:03s
epoch 22 | loss: 0.6703  | train_balanced_accuracy: 0.5194  | train_logloss: 0.67104 | train_f1_macro: 0.4712  | valid_balanced_accuracy: 0.51191 | valid_logloss: 0.67493 | valid_f1_macro: 0.45844 |  0:09:24s
epoch 23 | loss: 0.66807 | train_balanced_accuracy: 0.53434 | train_logloss: 0.66966 | train_f1_macro: 0.49953 | valid_balanced_accuracy: 0.52327 | valid_logloss: 0.67451 | valid_f1_macro: 0.48287 |  0:09:46s
epoch 24 | loss: 0.66763 | train_balanced_accuracy: 0.52516 | train_logloss: 0.66604 | train_f1_macro: 0.47855 | valid_balanced_accuracy: 0.52406 | valid_logloss: 0.66834 | valid_f1_macro: 0.47572 |  0:10:08s
epoch 25 | loss: 0.66659 | train_balanced_accuracy: 0.51892 | train_logloss: 0.66928 | train_f1_macro: 0.44675 | valid_balanced_accuracy: 0.51788 | valid_logloss: 0.67007 | valid_f1_macro: 0.4451  |  0:10:29s
epoch 26 | loss: 0.67115 | train_balanced_accuracy: 0.5108  | train_logloss: 0.67021 | train_f1_macro: 0.42791 | valid_balanced_accuracy: 0.51161 | valid_logloss: 0.6711  | valid_f1_macro: 0.4261  |  0:10:51s

Early stopping occurred at epoch 26 with best_epoch = 6 and best_valid_f1_macro = 0.4979
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[CV 1/5; 7/7] END classifier__estimator=TabNetClassifierTuner(n_d=8, n_a=8, n_steps=3, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=1, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=None, output_dim=None, device_name='cpu', n_shared_decoder=1, n_indep_decoder=1, use_embeddings=True, threshold_categorical_features=150, use_cat_emb_dim=True, fit_eval_metric=['balanced_accuracy', 'logloss', <class 'pytorch_tabnet_tuner.tab_model_tuner.F1ScoreMacro'>], fit_weights=0, fit_batch_size=1024, fit_virtual_batch_size=128), classifier__estimator__cat_emb_dim=20, classifier__estimator__clip_value=1, classifier__estimator__gamma=2.0, classifier__estimator__lambda_sparse=0.001, classifier__estimator__mask_type=sparsemax, classifier__estimator__momentum=0.4, classifier__estimator__n_a=64, classifier__estimator__n_independent=5, classifier__estimator__n_shared=5, classifier__estimator__n_steps=10, classifier__estimator__optimizer_fn=<class 'torch.optim.adam.Adam'>, classifier__estimator__optimizer_params={'lr': 0.02}, classifier__estimator__scheduler_fn=<class 'torch.optim.lr_scheduler.StepLR'>, classifier__estimator__scheduler_params={'step_size': 10, 'gamma': 0.95}, classifier__estimator__seed=42, classifier__estimator__verbose=1;, score=0.380 total time=11.0min
[CV 2/5; 7/7] START classifier__estimator=TabNetClassifierTuner(n_d=8, n_a=8, n_steps=3, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=1, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=None, output_dim=None, device_name='cpu', n_shared_decoder=1, n_indep_decoder=1, use_embeddings=True, threshold_categorical_features=150, use_cat_emb_dim=True, fit_eval_metric=['balanced_accuracy', 'logloss', <class 'pytorch_tabnet_tuner.tab_model_tuner.F1ScoreMacro'>], fit_weights=0, fit_batch_size=1024, fit_virtual_batch_size=128), classifier__estimator__cat_emb_dim=20, classifier__estimator__clip_value=1, classifier__estimator__gamma=2.0, classifier__estimator__lambda_sparse=0.001, classifier__estimator__mask_type=sparsemax, classifier__estimator__momentum=0.4, classifier__estimator__n_a=64, classifier__estimator__n_independent=5, classifier__estimator__n_shared=5, classifier__estimator__n_steps=10, classifier__estimator__optimizer_fn=<class 'torch.optim.adam.Adam'>, classifier__estimator__optimizer_params={'lr': 0.02}, classifier__estimator__scheduler_fn=<class 'torch.optim.lr_scheduler.StepLR'>, classifier__estimator__scheduler_params={'step_size': 10, 'gamma': 0.95}, classifier__estimator__seed=42, classifier__estimator__verbose=1
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu
  warnings.warn(f"Device used : {self.device}")
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: n_d changed from 8 to 64
  warnings.warn(wrn_msg)
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: cat_dims changed from [] to [29, 5, 7, 10, 13, 15, 7, 10, 23, 18, 27, 25, 14, 22, 31, 19, 23]
  warnings.warn(wrn_msg)
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: cat_emb_dim changed from 20 to [14, 2, 3, 5, 6, 7, 3, 5, 11, 9, 13, 12, 7, 11, 15, 9, 11]
  warnings.warn(wrn_msg)
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: cat_idxs changed from [] to [0, 1, 2, 3, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]
  warnings.warn(wrn_msg)
epoch 0  | loss: 4.83684 | train_balanced_accuracy: 0.49952 | train_logloss: 1.5382  | train_f1_macro: 0.48443 | valid_balanced_accuracy: 0.48929 | valid_logloss: 1.57435 | valid_f1_macro: 0.47217 |  0:00:22s
epoch 1  | loss: 1.59155 | train_balanced_accuracy: 0.50361 | train_logloss: 1.47017 | train_f1_macro: 0.43089 | valid_balanced_accuracy: 0.50581 | valid_logloss: 1.42118 | valid_f1_macro: 0.4379  |  0:00:44s
epoch 2  | loss: 3.9948  | train_balanced_accuracy: 0.50074 | train_logloss: 2.63314 | train_f1_macro: 0.33884 | valid_balanced_accuracy: 0.49875 | valid_logloss: 2.64024 | valid_f1_macro: 0.33912 |  0:01:07s
epoch 3  | loss: 1.45757 | train_balanced_accuracy: 0.51381 | train_logloss: 0.76705 | train_f1_macro: 0.48422 | valid_balanced_accuracy: 0.51508 | valid_logloss: 0.75692 | valid_f1_macro: 0.48771 |  0:01:29s
epoch 4  | loss: 1.66256 | train_balanced_accuracy: 0.50891 | train_logloss: 1.07841 | train_f1_macro: 0.46628 | valid_balanced_accuracy: 0.50783 | valid_logloss: 1.07236 | valid_f1_macro: 0.46176 |  0:01:51s
epoch 5  | loss: 1.01216 | train_balanced_accuracy: 0.51778 | train_logloss: 0.69288 | train_f1_macro: 0.51678 | valid_balanced_accuracy: 0.5108  | valid_logloss: 0.69644 | valid_f1_macro: 0.51059 |  0:02:13s
epoch 6  | loss: 0.71603 | train_balanced_accuracy: 0.49906 | train_logloss: 0.69407 | train_f1_macro: 0.49313 | valid_balanced_accuracy: 0.49489 | valid_logloss: 0.69538 | valid_f1_macro: 0.48887 |  0:02:36s
epoch 7  | loss: 0.68183 | train_balanced_accuracy: 0.49919 | train_logloss: 0.69563 | train_f1_macro: 0.48508 | valid_balanced_accuracy: 0.4914  | valid_logloss: 0.69744 | valid_f1_macro: 0.47635 |  0:02:58s
epoch 8  | loss: 0.67245 | train_balanced_accuracy: 0.50423 | train_logloss: 0.67347 | train_f1_macro: 0.39443 | valid_balanced_accuracy: 0.50467 | valid_logloss: 0.67305 | valid_f1_macro: 0.39203 |  0:03:21s
epoch 9  | loss: 0.67012 | train_balanced_accuracy: 0.52277 | train_logloss: 0.67276 | train_f1_macro: 0.46914 | valid_balanced_accuracy: 0.52166 | valid_logloss: 0.67345 | valid_f1_macro: 0.46933 |  0:03:44s
epoch 10 | loss: 0.66825 | train_balanced_accuracy: 0.50291 | train_logloss: 0.67166 | train_f1_macro: 0.39033 | valid_balanced_accuracy: 0.50488 | valid_logloss: 0.67379 | valid_f1_macro: 0.39133 |  0:04:06s
epoch 11 | loss: 0.67053 | train_balanced_accuracy: 0.52375 | train_logloss: 0.67185 | train_f1_macro: 0.48367 | valid_balanced_accuracy: 0.5326  | valid_logloss: 0.66995 | valid_f1_macro: 0.49401 |  0:04:28s
epoch 12 | loss: 0.67103 | train_balanced_accuracy: 0.52518 | train_logloss: 0.67758 | train_f1_macro: 0.50049 | valid_balanced_accuracy: 0.52178 | valid_logloss: 0.67834 | valid_f1_macro: 0.49766 |  0:04:50s
epoch 13 | loss: 0.67183 | train_balanced_accuracy: 0.51765 | train_logloss: 0.66662 | train_f1_macro: 0.43112 | valid_balanced_accuracy: 0.51045 | valid_logloss: 0.66711 | valid_f1_macro: 0.4221  |  0:05:12s
epoch 14 | loss: 0.67143 | train_balanced_accuracy: 0.55878 | train_logloss: 0.67023 | train_f1_macro: 0.55243 | valid_balanced_accuracy: 0.5546  | valid_logloss: 0.67013 | valid_f1_macro: 0.54857 |  0:05:34s
epoch 15 | loss: 0.6716  | train_balanced_accuracy: 0.53346 | train_logloss: 0.67182 | train_f1_macro: 0.50147 | valid_balanced_accuracy: 0.5291  | valid_logloss: 0.67269 | valid_f1_macro: 0.49824 |  0:05:56s
epoch 16 | loss: 0.67122 | train_balanced_accuracy: 0.5225  | train_logloss: 0.67206 | train_f1_macro: 0.4703  | valid_balanced_accuracy: 0.51573 | valid_logloss: 0.67074 | valid_f1_macro: 0.46218 |  0:06:18s
epoch 17 | loss: 0.67098 | train_balanced_accuracy: 0.51333 | train_logloss: 0.67154 | train_f1_macro: 0.41864 | valid_balanced_accuracy: 0.51503 | valid_logloss: 0.67202 | valid_f1_macro: 0.4184  |  0:06:40s
epoch 18 | loss: 0.66959 | train_balanced_accuracy: 0.53566 | train_logloss: 0.66873 | train_f1_macro: 0.50724 | valid_balanced_accuracy: 0.52567 | valid_logloss: 0.6701  | valid_f1_macro: 0.49447 |  0:07:02s
epoch 19 | loss: 0.67104 | train_balanced_accuracy: 0.5221  | train_logloss: 0.66599 | train_f1_macro: 0.47055 | valid_balanced_accuracy: 0.52253 | valid_logloss: 0.66378 | valid_f1_macro: 0.47087 |  0:07:25s
epoch 20 | loss: 0.66717 | train_balanced_accuracy: 0.52653 | train_logloss: 0.67848 | train_f1_macro: 0.47099 | valid_balanced_accuracy: 0.52353 | valid_logloss: 0.67296 | valid_f1_macro: 0.46868 |  0:07:47s
epoch 21 | loss: 0.66412 | train_balanced_accuracy: 0.54547 | train_logloss: 0.66527 | train_f1_macro: 0.51429 | valid_balanced_accuracy: 0.53977 | valid_logloss: 0.6652  | valid_f1_macro: 0.51067 |  0:08:09s
epoch 22 | loss: 0.66515 | train_balanced_accuracy: 0.53452 | train_logloss: 0.66709 | train_f1_macro: 0.48728 | valid_balanced_accuracy: 0.52682 | valid_logloss: 0.66743 | valid_f1_macro: 0.47932 |  0:08:31s
epoch 23 | loss: 0.66943 | train_balanced_accuracy: 0.53659 | train_logloss: 0.66522 | train_f1_macro: 0.4916  | valid_balanced_accuracy: 0.52261 | valid_logloss: 0.66685 | valid_f1_macro: 0.47418 |  0:08:53s
epoch 24 | loss: 0.66742 | train_balanced_accuracy: 0.53849 | train_logloss: 0.66657 | train_f1_macro: 0.50648 | valid_balanced_accuracy: 0.53092 | valid_logloss: 0.66828 | valid_f1_macro: 0.49781 |  0:09:15s
epoch 25 | loss: 0.66556 | train_balanced_accuracy: 0.5418  | train_logloss: 0.66464 | train_f1_macro: 0.51826 | valid_balanced_accuracy: 0.53385 | valid_logloss: 0.66806 | valid_f1_macro: 0.50896 |  0:09:37s
epoch 26 | loss: 0.66471 | train_balanced_accuracy: 0.55464 | train_logloss: 0.68129 | train_f1_macro: 0.5548  | valid_balanced_accuracy: 0.55523 | valid_logloss: 0.6819  | valid_f1_macro: 0.55531 |  0:09:59s
epoch 27 | loss: 0.66653 | train_balanced_accuracy: 0.54396 | train_logloss: 0.68251 | train_f1_macro: 0.52351 | valid_balanced_accuracy: 0.53327 | valid_logloss: 0.68204 | valid_f1_macro: 0.51149 |  0:10:21s
epoch 28 | loss: 0.66397 | train_balanced_accuracy: 0.53507 | train_logloss: 0.66265 | train_f1_macro: 0.4837  | valid_balanced_accuracy: 0.52677 | valid_logloss: 0.66338 | valid_f1_macro: 0.47087 |  0:10:43s
epoch 29 | loss: 0.66357 | train_balanced_accuracy: 0.56738 | train_logloss: 0.66747 | train_f1_macro: 0.56755 | valid_balanced_accuracy: 0.56701 | valid_logloss: 0.66839 | valid_f1_macro: 0.56723 |  0:11:05s
epoch 30 | loss: 0.66423 | train_balanced_accuracy: 0.52633 | train_logloss: 0.66261 | train_f1_macro: 0.45862 | valid_balanced_accuracy: 0.5193  | valid_logloss: 0.66437 | valid_f1_macro: 0.44917 |  0:11:27s
epoch 31 | loss: 0.66346 | train_balanced_accuracy: 0.53954 | train_logloss: 0.6635  | train_f1_macro: 0.50716 | valid_balanced_accuracy: 0.53381 | valid_logloss: 0.66322 | valid_f1_macro: 0.49969 |  0:11:49s
epoch 32 | loss: 0.66344 | train_balanced_accuracy: 0.56028 | train_logloss: 0.66131 | train_f1_macro: 0.54412 | valid_balanced_accuracy: 0.55391 | valid_logloss: 0.66208 | valid_f1_macro: 0.53788 |  0:12:12s
epoch 33 | loss: 0.6625  | train_balanced_accuracy: 0.54727 | train_logloss: 0.66044 | train_f1_macro: 0.51635 | valid_balanced_accuracy: 0.537   | valid_logloss: 0.66376 | valid_f1_macro: 0.50163 |  0:12:34s
epoch 34 | loss: 0.66269 | train_balanced_accuracy: 0.53664 | train_logloss: 0.66883 | train_f1_macro: 0.49652 | valid_balanced_accuracy: 0.53297 | valid_logloss: 0.66699 | valid_f1_macro: 0.49037 |  0:12:56s
epoch 35 | loss: 0.66363 | train_balanced_accuracy: 0.53963 | train_logloss: 0.66389 | train_f1_macro: 0.50313 | valid_balanced_accuracy: 0.53502 | valid_logloss: 0.66614 | valid_f1_macro: 0.49686 |  0:13:18s
epoch 36 | loss: 0.66348 | train_balanced_accuracy: 0.54683 | train_logloss: 0.66023 | train_f1_macro: 0.52695 | valid_balanced_accuracy: 0.53859 | valid_logloss: 0.66204 | valid_f1_macro: 0.51632 |  0:13:41s
epoch 37 | loss: 0.66215 | train_balanced_accuracy: 0.53796 | train_logloss: 0.66339 | train_f1_macro: 0.49564 | valid_balanced_accuracy: 0.53114 | valid_logloss: 0.6665  | valid_f1_macro: 0.48288 |  0:14:03s
epoch 38 | loss: 0.66427 | train_balanced_accuracy: 0.5338  | train_logloss: 0.66848 | train_f1_macro: 0.48429 | valid_balanced_accuracy: 0.52777 | valid_logloss: 0.67185 | valid_f1_macro: 0.47662 |  0:14:25s
epoch 39 | loss: 0.66354 | train_balanced_accuracy: 0.5511  | train_logloss: 0.66349 | train_f1_macro: 0.54025 | valid_balanced_accuracy: 0.54221 | valid_logloss: 0.66408 | valid_f1_macro: 0.52936 |  0:14:47s
epoch 40 | loss: 0.66483 | train_balanced_accuracy: 0.51674 | train_logloss: 0.6669  | train_f1_macro: 0.43467 | valid_balanced_accuracy: 0.51659 | valid_logloss: 0.6645  | valid_f1_macro: 0.43154 |  0:15:09s
epoch 41 | loss: 0.66693 | train_balanced_accuracy: 0.5449  | train_logloss: 0.66266 | train_f1_macro: 0.52195 | valid_balanced_accuracy: 0.53445 | valid_logloss: 0.66223 | valid_f1_macro: 0.50892 |  0:15:31s
epoch 42 | loss: 0.66622 | train_balanced_accuracy: 0.54352 | train_logloss: 0.66476 | train_f1_macro: 0.52331 | valid_balanced_accuracy: 0.53517 | valid_logloss: 0.66511 | valid_f1_macro: 0.5135  |  0:15:53s
epoch 43 | loss: 0.66467 | train_balanced_accuracy: 0.54414 | train_logloss: 0.66723 | train_f1_macro: 0.53129 | valid_balanced_accuracy: 0.52653 | valid_logloss: 0.66891 | valid_f1_macro: 0.51133 |  0:16:15s
epoch 44 | loss: 0.66489 | train_balanced_accuracy: 0.52959 | train_logloss: 0.66429 | train_f1_macro: 0.47065 | valid_balanced_accuracy: 0.51973 | valid_logloss: 0.66669 | valid_f1_macro: 0.45943 |  0:16:37s
epoch 45 | loss: 0.66331 | train_balanced_accuracy: 0.55058 | train_logloss: 0.66297 | train_f1_macro: 0.53783 | valid_balanced_accuracy: 0.53791 | valid_logloss: 0.66587 | valid_f1_macro: 0.52321 |  0:16:59s
epoch 46 | loss: 0.66128 | train_balanced_accuracy: 0.53524 | train_logloss: 0.66064 | train_f1_macro: 0.48642 | valid_balanced_accuracy: 0.52358 | valid_logloss: 0.66348 | valid_f1_macro: 0.46614 |  0:17:21s
epoch 47 | loss: 0.66159 | train_balanced_accuracy: 0.53728 | train_logloss: 0.65984 | train_f1_macro: 0.4985  | valid_balanced_accuracy: 0.52519 | valid_logloss: 0.66187 | valid_f1_macro: 0.4819  |  0:17:44s
epoch 48 | loss: 0.66093 | train_balanced_accuracy: 0.53615 | train_logloss: 0.66022 | train_f1_macro: 0.48989 | valid_balanced_accuracy: 0.53109 | valid_logloss: 0.66032 | valid_f1_macro: 0.47916 |  0:18:06s
epoch 49 | loss: 0.66195 | train_balanced_accuracy: 0.54197 | train_logloss: 0.66143 | train_f1_macro: 0.51108 | valid_balanced_accuracy: 0.53352 | valid_logloss: 0.66215 | valid_f1_macro: 0.49844 |  0:18:28s

Early stopping occurred at epoch 49 with best_epoch = 29 and best_valid_f1_macro = 0.56723
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[CV 2/5; 7/7] END classifier__estimator=TabNetClassifierTuner(n_d=8, n_a=8, n_steps=3, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=1, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=None, output_dim=None, device_name='cpu', n_shared_decoder=1, n_indep_decoder=1, use_embeddings=True, threshold_categorical_features=150, use_cat_emb_dim=True, fit_eval_metric=['balanced_accuracy', 'logloss', <class 'pytorch_tabnet_tuner.tab_model_tuner.F1ScoreMacro'>], fit_weights=0, fit_batch_size=1024, fit_virtual_batch_size=128), classifier__estimator__cat_emb_dim=20, classifier__estimator__clip_value=1, classifier__estimator__gamma=2.0, classifier__estimator__lambda_sparse=0.001, classifier__estimator__mask_type=sparsemax, classifier__estimator__momentum=0.4, classifier__estimator__n_a=64, classifier__estimator__n_independent=5, classifier__estimator__n_shared=5, classifier__estimator__n_steps=10, classifier__estimator__optimizer_fn=<class 'torch.optim.adam.Adam'>, classifier__estimator__optimizer_params={'lr': 0.02}, classifier__estimator__scheduler_fn=<class 'torch.optim.lr_scheduler.StepLR'>, classifier__estimator__scheduler_params={'step_size': 10, 'gamma': 0.95}, classifier__estimator__seed=42, classifier__estimator__verbose=1;, score=0.528 total time=18.6min
[CV 3/5; 7/7] START classifier__estimator=TabNetClassifierTuner(n_d=8, n_a=8, n_steps=3, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=1, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=None, output_dim=None, device_name='cpu', n_shared_decoder=1, n_indep_decoder=1, use_embeddings=True, threshold_categorical_features=150, use_cat_emb_dim=True, fit_eval_metric=['balanced_accuracy', 'logloss', <class 'pytorch_tabnet_tuner.tab_model_tuner.F1ScoreMacro'>], fit_weights=0, fit_batch_size=1024, fit_virtual_batch_size=128), classifier__estimator__cat_emb_dim=20, classifier__estimator__clip_value=1, classifier__estimator__gamma=2.0, classifier__estimator__lambda_sparse=0.001, classifier__estimator__mask_type=sparsemax, classifier__estimator__momentum=0.4, classifier__estimator__n_a=64, classifier__estimator__n_independent=5, classifier__estimator__n_shared=5, classifier__estimator__n_steps=10, classifier__estimator__optimizer_fn=<class 'torch.optim.adam.Adam'>, classifier__estimator__optimizer_params={'lr': 0.02}, classifier__estimator__scheduler_fn=<class 'torch.optim.lr_scheduler.StepLR'>, classifier__estimator__scheduler_params={'step_size': 10, 'gamma': 0.95}, classifier__estimator__seed=42, classifier__estimator__verbose=1
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu
  warnings.warn(f"Device used : {self.device}")
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: n_d changed from 8 to 64
  warnings.warn(wrn_msg)
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: cat_dims changed from [] to [24, 5, 11, 10, 11, 18, 6, 12, 28, 27, 26, 16, 17, 16, 27, 33, 33]
  warnings.warn(wrn_msg)
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: cat_emb_dim changed from 20 to [12, 2, 5, 5, 5, 9, 3, 6, 14, 13, 13, 8, 8, 8, 13, 16, 16]
  warnings.warn(wrn_msg)
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: cat_idxs changed from [] to [0, 1, 2, 3, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]
  warnings.warn(wrn_msg)
epoch 0  | loss: 2.31873 | train_balanced_accuracy: 0.49836 | train_logloss: 1.60929 | train_f1_macro: 0.49703 | valid_balanced_accuracy: 0.50625 | valid_logloss: 1.57861 | valid_f1_macro: 0.50524 |  0:00:22s
epoch 1  | loss: 2.92033 | train_balanced_accuracy: 0.52065 | train_logloss: 1.40824 | train_f1_macro: 0.51578 | valid_balanced_accuracy: 0.51898 | valid_logloss: 1.40103 | valid_f1_macro: 0.51425 |  0:00:45s
epoch 2  | loss: 1.68027 | train_balanced_accuracy: 0.49853 | train_logloss: 1.22145 | train_f1_macro: 0.38087 | valid_balanced_accuracy: 0.49734 | valid_logloss: 1.24486 | valid_f1_macro: 0.3779  |  0:01:08s
epoch 3  | loss: 3.17508 | train_balanced_accuracy: 0.50664 | train_logloss: 1.58619 | train_f1_macro: 0.41768 | valid_balanced_accuracy: 0.50496 | valid_logloss: 1.54258 | valid_f1_macro: 0.41736 |  0:01:30s
epoch 4  | loss: 1.60051 | train_balanced_accuracy: 0.49991 | train_logloss: 1.9068  | train_f1_macro: 0.37479 | valid_balanced_accuracy: 0.50208 | valid_logloss: 1.85895 | valid_f1_macro: 0.37897 |  0:01:53s
epoch 5  | loss: 1.10199 | train_balanced_accuracy: 0.4995  | train_logloss: 0.96995 | train_f1_macro: 0.37459 | valid_balanced_accuracy: 0.49945 | valid_logloss: 0.98331 | valid_f1_macro: 0.37329 |  0:02:16s
epoch 6  | loss: 0.86596 | train_balanced_accuracy: 0.53404 | train_logloss: 0.71485 | train_f1_macro: 0.53296 | valid_balanced_accuracy: 0.53418 | valid_logloss: 0.71662 | valid_f1_macro: 0.53294 |  0:02:38s
epoch 7  | loss: 0.74025 | train_balanced_accuracy: 0.49985 | train_logloss: 0.71504 | train_f1_macro: 0.37209 | valid_balanced_accuracy: 0.49913 | valid_logloss: 0.71823 | valid_f1_macro: 0.37135 |  0:03:01s
epoch 8  | loss: 0.7135  | train_balanced_accuracy: 0.53662 | train_logloss: 0.69384 | train_f1_macro: 0.53671 | valid_balanced_accuracy: 0.52872 | valid_logloss: 0.69764 | valid_f1_macro: 0.52878 |  0:03:24s
epoch 9  | loss: 0.67453 | train_balanced_accuracy: 0.50026 | train_logloss: 0.68188 | train_f1_macro: 0.37115 | valid_balanced_accuracy: 0.49963 | valid_logloss: 0.68273 | valid_f1_macro: 0.37023 |  0:03:47s
epoch 10 | loss: 0.67333 | train_balanced_accuracy: 0.51666 | train_logloss: 0.67465 | train_f1_macro: 0.44421 | valid_balanced_accuracy: 0.50903 | valid_logloss: 0.67587 | valid_f1_macro: 0.43305 |  0:04:09s
epoch 11 | loss: 0.67203 | train_balanced_accuracy: 0.50623 | train_logloss: 0.67397 | train_f1_macro: 0.41534 | valid_balanced_accuracy: 0.50017 | valid_logloss: 0.67668 | valid_f1_macro: 0.40976 |  0:04:32s
epoch 12 | loss: 0.6711  | train_balanced_accuracy: 0.5176  | train_logloss: 0.67336 | train_f1_macro: 0.44035 | valid_balanced_accuracy: 0.50879 | valid_logloss: 0.67463 | valid_f1_macro: 0.42776 |  0:04:56s
epoch 13 | loss: 0.67204 | train_balanced_accuracy: 0.5349  | train_logloss: 0.67962 | train_f1_macro: 0.52387 | valid_balanced_accuracy: 0.54161 | valid_logloss: 0.67701 | valid_f1_macro: 0.53266 |  0:05:19s
epoch 14 | loss: 0.67587 | train_balanced_accuracy: 0.51716 | train_logloss: 0.67792 | train_f1_macro: 0.47276 | valid_balanced_accuracy: 0.51871 | valid_logloss: 0.67327 | valid_f1_macro: 0.47585 |  0:05:41s
epoch 15 | loss: 0.6717  | train_balanced_accuracy: 0.51777 | train_logloss: 0.67215 | train_f1_macro: 0.47126 | valid_balanced_accuracy: 0.51839 | valid_logloss: 0.67113 | valid_f1_macro: 0.47342 |  0:06:04s
epoch 16 | loss: 0.67112 | train_balanced_accuracy: 0.51276 | train_logloss: 0.67086 | train_f1_macro: 0.41635 | valid_balanced_accuracy: 0.50699 | valid_logloss: 0.6713  | valid_f1_macro: 0.40642 |  0:06:26s
epoch 17 | loss: 0.67072 | train_balanced_accuracy: 0.51574 | train_logloss: 0.67802 | train_f1_macro: 0.44258 | valid_balanced_accuracy: 0.51171 | valid_logloss: 0.67695 | valid_f1_macro: 0.43454 |  0:06:49s
epoch 18 | loss: 0.66904 | train_balanced_accuracy: 0.50632 | train_logloss: 0.66808 | train_f1_macro: 0.39567 | valid_balanced_accuracy: 0.50272 | valid_logloss: 0.66756 | valid_f1_macro: 0.38856 |  0:07:14s
epoch 19 | loss: 0.66888 | train_balanced_accuracy: 0.52864 | train_logloss: 0.66587 | train_f1_macro: 0.49462 | valid_balanced_accuracy: 0.52641 | valid_logloss: 0.66611 | valid_f1_macro: 0.49395 |  0:07:36s
epoch 20 | loss: 0.66939 | train_balanced_accuracy: 0.51493 | train_logloss: 0.67017 | train_f1_macro: 0.45099 | valid_balanced_accuracy: 0.51296 | valid_logloss: 0.67148 | valid_f1_macro: 0.44822 |  0:07:59s
epoch 21 | loss: 0.66841 | train_balanced_accuracy: 0.52672 | train_logloss: 0.66892 | train_f1_macro: 0.48801 | valid_balanced_accuracy: 0.51876 | valid_logloss: 0.67181 | valid_f1_macro: 0.47781 |  0:08:22s
epoch 22 | loss: 0.66895 | train_balanced_accuracy: 0.52891 | train_logloss: 0.66774 | train_f1_macro: 0.4855  | valid_balanced_accuracy: 0.52408 | valid_logloss: 0.66821 | valid_f1_macro: 0.47679 |  0:08:45s
epoch 23 | loss: 0.66646 | train_balanced_accuracy: 0.52062 | train_logloss: 0.66629 | train_f1_macro: 0.44401 | valid_balanced_accuracy: 0.51651 | valid_logloss: 0.66781 | valid_f1_macro: 0.43772 |  0:09:08s
epoch 24 | loss: 0.66755 | train_balanced_accuracy: 0.53524 | train_logloss: 0.66729 | train_f1_macro: 0.51556 | valid_balanced_accuracy: 0.53696 | valid_logloss: 0.66708 | valid_f1_macro: 0.51887 |  0:09:31s
epoch 25 | loss: 0.66678 | train_balanced_accuracy: 0.51018 | train_logloss: 0.66528 | train_f1_macro: 0.40849 | valid_balanced_accuracy: 0.50791 | valid_logloss: 0.6658  | valid_f1_macro: 0.40168 |  0:09:55s
epoch 26 | loss: 0.66703 | train_balanced_accuracy: 0.52531 | train_logloss: 0.66741 | train_f1_macro: 0.47292 | valid_balanced_accuracy: 0.52582 | valid_logloss: 0.66639 | valid_f1_macro: 0.47224 |  0:10:17s

Early stopping occurred at epoch 26 with best_epoch = 6 and best_valid_f1_macro = 0.53294
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[CV 3/5; 7/7] END classifier__estimator=TabNetClassifierTuner(n_d=8, n_a=8, n_steps=3, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=1, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=None, output_dim=None, device_name='cpu', n_shared_decoder=1, n_indep_decoder=1, use_embeddings=True, threshold_categorical_features=150, use_cat_emb_dim=True, fit_eval_metric=['balanced_accuracy', 'logloss', <class 'pytorch_tabnet_tuner.tab_model_tuner.F1ScoreMacro'>], fit_weights=0, fit_batch_size=1024, fit_virtual_batch_size=128), classifier__estimator__cat_emb_dim=20, classifier__estimator__clip_value=1, classifier__estimator__gamma=2.0, classifier__estimator__lambda_sparse=0.001, classifier__estimator__mask_type=sparsemax, classifier__estimator__momentum=0.4, classifier__estimator__n_a=64, classifier__estimator__n_independent=5, classifier__estimator__n_shared=5, classifier__estimator__n_steps=10, classifier__estimator__optimizer_fn=<class 'torch.optim.adam.Adam'>, classifier__estimator__optimizer_params={'lr': 0.02}, classifier__estimator__scheduler_fn=<class 'torch.optim.lr_scheduler.StepLR'>, classifier__estimator__scheduler_params={'step_size': 10, 'gamma': 0.95}, classifier__estimator__seed=42, classifier__estimator__verbose=1;, score=0.474 total time=10.5min
[CV 4/5; 7/7] START classifier__estimator=TabNetClassifierTuner(n_d=8, n_a=8, n_steps=3, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=1, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=None, output_dim=None, device_name='cpu', n_shared_decoder=1, n_indep_decoder=1, use_embeddings=True, threshold_categorical_features=150, use_cat_emb_dim=True, fit_eval_metric=['balanced_accuracy', 'logloss', <class 'pytorch_tabnet_tuner.tab_model_tuner.F1ScoreMacro'>], fit_weights=0, fit_batch_size=1024, fit_virtual_batch_size=128), classifier__estimator__cat_emb_dim=20, classifier__estimator__clip_value=1, classifier__estimator__gamma=2.0, classifier__estimator__lambda_sparse=0.001, classifier__estimator__mask_type=sparsemax, classifier__estimator__momentum=0.4, classifier__estimator__n_a=64, classifier__estimator__n_independent=5, classifier__estimator__n_shared=5, classifier__estimator__n_steps=10, classifier__estimator__optimizer_fn=<class 'torch.optim.adam.Adam'>, classifier__estimator__optimizer_params={'lr': 0.02}, classifier__estimator__scheduler_fn=<class 'torch.optim.lr_scheduler.StepLR'>, classifier__estimator__scheduler_params={'step_size': 10, 'gamma': 0.95}, classifier__estimator__seed=42, classifier__estimator__verbose=1
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu
  warnings.warn(f"Device used : {self.device}")
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: n_d changed from 8 to 64
  warnings.warn(wrn_msg)
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: cat_dims changed from [] to [30, 3, 5, 6, 14, 12, 6, 10, 41, 29, 18, 25, 18, 16, 31, 29, 30]
  warnings.warn(wrn_msg)
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: cat_emb_dim changed from 20 to [15, 1, 2, 3, 7, 6, 3, 5, 20, 14, 9, 12, 9, 8, 15, 14, 15]
  warnings.warn(wrn_msg)
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: cat_idxs changed from [] to [0, 1, 2, 3, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]
  warnings.warn(wrn_msg)
[CV 4/5; 7/7] END classifier__estimator=TabNetClassifierTuner(n_d=8, n_a=8, n_steps=3, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=1, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=None, output_dim=None, device_name='cpu', n_shared_decoder=1, n_indep_decoder=1, use_embeddings=True, threshold_categorical_features=150, use_cat_emb_dim=True, fit_eval_metric=['balanced_accuracy', 'logloss', <class 'pytorch_tabnet_tuner.tab_model_tuner.F1ScoreMacro'>], fit_weights=0, fit_batch_size=1024, fit_virtual_batch_size=128), classifier__estimator__cat_emb_dim=20, classifier__estimator__clip_value=1, classifier__estimator__gamma=2.0, classifier__estimator__lambda_sparse=0.001, classifier__estimator__mask_type=sparsemax, classifier__estimator__momentum=0.4, classifier__estimator__n_a=64, classifier__estimator__n_independent=5, classifier__estimator__n_shared=5, classifier__estimator__n_steps=10, classifier__estimator__optimizer_fn=<class 'torch.optim.adam.Adam'>, classifier__estimator__optimizer_params={'lr': 0.02}, classifier__estimator__scheduler_fn=<class 'torch.optim.lr_scheduler.StepLR'>, classifier__estimator__scheduler_params={'step_size': 10, 'gamma': 0.95}, classifier__estimator__seed=42, classifier__estimator__verbose=1;, score=nan total time=  15.7s
[CV 5/5; 7/7] START classifier__estimator=TabNetClassifierTuner(n_d=8, n_a=8, n_steps=3, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=1, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=None, output_dim=None, device_name='cpu', n_shared_decoder=1, n_indep_decoder=1, use_embeddings=True, threshold_categorical_features=150, use_cat_emb_dim=True, fit_eval_metric=['balanced_accuracy', 'logloss', <class 'pytorch_tabnet_tuner.tab_model_tuner.F1ScoreMacro'>], fit_weights=0, fit_batch_size=1024, fit_virtual_batch_size=128), classifier__estimator__cat_emb_dim=20, classifier__estimator__clip_value=1, classifier__estimator__gamma=2.0, classifier__estimator__lambda_sparse=0.001, classifier__estimator__mask_type=sparsemax, classifier__estimator__momentum=0.4, classifier__estimator__n_a=64, classifier__estimator__n_independent=5, classifier__estimator__n_shared=5, classifier__estimator__n_steps=10, classifier__estimator__optimizer_fn=<class 'torch.optim.adam.Adam'>, classifier__estimator__optimizer_params={'lr': 0.02}, classifier__estimator__scheduler_fn=<class 'torch.optim.lr_scheduler.StepLR'>, classifier__estimator__scheduler_params={'step_size': 10, 'gamma': 0.95}, classifier__estimator__seed=42, classifier__estimator__verbose=1
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu
  warnings.warn(f"Device used : {self.device}")
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: n_d changed from 8 to 64
  warnings.warn(wrn_msg)
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: cat_dims changed from [] to [30, 4, 4, 4, 11, 16, 7, 16, 36, 26, 23, 26, 24, 15, 25, 29, 29]
  warnings.warn(wrn_msg)
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: cat_emb_dim changed from 20 to [15, 2, 2, 2, 5, 8, 3, 8, 18, 13, 11, 13, 12, 7, 12, 14, 14]
  warnings.warn(wrn_msg)
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: cat_idxs changed from [] to [0, 1, 2, 3, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]
  warnings.warn(wrn_msg)
[CV 5/5; 7/7] END classifier__estimator=TabNetClassifierTuner(n_d=8, n_a=8, n_steps=3, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=1, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=None, output_dim=None, device_name='cpu', n_shared_decoder=1, n_indep_decoder=1, use_embeddings=True, threshold_categorical_features=150, use_cat_emb_dim=True, fit_eval_metric=['balanced_accuracy', 'logloss', <class 'pytorch_tabnet_tuner.tab_model_tuner.F1ScoreMacro'>], fit_weights=0, fit_batch_size=1024, fit_virtual_batch_size=128), classifier__estimator__cat_emb_dim=20, classifier__estimator__clip_value=1, classifier__estimator__gamma=2.0, classifier__estimator__lambda_sparse=0.001, classifier__estimator__mask_type=sparsemax, classifier__estimator__momentum=0.4, classifier__estimator__n_a=64, classifier__estimator__n_independent=5, classifier__estimator__n_shared=5, classifier__estimator__n_steps=10, classifier__estimator__optimizer_fn=<class 'torch.optim.adam.Adam'>, classifier__estimator__optimizer_params={'lr': 0.02}, classifier__estimator__scheduler_fn=<class 'torch.optim.lr_scheduler.StepLR'>, classifier__estimator__scheduler_params={'step_size': 10, 'gamma': 0.95}, classifier__estimator__seed=42, classifier__estimator__verbose=1;, score=nan total time=  15.8s
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
2 fits failed out of a total of 35.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/sklearn_tuner/model_selection_tuner/_validation_tuner.py", line 187, in _fit_and_score_tuner
    estimator.fit(X_train, y_train, **fit_params)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/imblearn/pipeline.py", line 297, in fit
    self._final_estimator.fit(Xt, yt, **fit_params_last_step)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/clf_switcher.py", line 20, in fit
    self.estimator.fit(x, y)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/pytorch_tabnet_tuner/tab_model_tuner.py", line 151, in fit
    super().fit(
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py", line 241, in fit
    self._train_epoch(train_dataloader)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py", line 457, in _train_epoch
    batch_logs = self._train_batch(X, y)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py", line 495, in _train_batch
    output, M_loss = self.network(X)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/tab_network.py", line 586, in forward
    return self.tabnet(x)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/tab_network.py", line 471, in forward
    steps_output, M_loss = self.encoder(x)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/tab_network.py", line 150, in forward
    x = self.initial_bn(x)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/torch/nn/functional.py", line 2448, in batch_norm
    _verify_batch_size(input.size())
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/torch/nn/functional.py", line 2416, in _verify_batch_size
    raise ValueError("Expected more than 1 value per channel when training, got input size {}".format(size))
ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 164])

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/sklearn_tuner/model_selection_tuner/_validation_tuner.py", line 187, in _fit_and_score_tuner
    estimator.fit(X_train, y_train, **fit_params)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/imblearn/pipeline.py", line 297, in fit
    self._final_estimator.fit(Xt, yt, **fit_params_last_step)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/clf_switcher.py", line 20, in fit
    self.estimator.fit(x, y)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/pytorch_tabnet_tuner/tab_model_tuner.py", line 151, in fit
    super().fit(
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py", line 241, in fit
    self._train_epoch(train_dataloader)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py", line 457, in _train_epoch
    batch_logs = self._train_batch(X, y)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py", line 495, in _train_batch
    output, M_loss = self.network(X)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/tab_network.py", line 586, in forward
    return self.tabnet(x)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/tab_network.py", line 471, in forward
    steps_output, M_loss = self.encoder(x)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/pytorch_tabnet/tab_network.py", line 150, in forward
    x = self.initial_bn(x)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/torch/nn/functional.py", line 2448, in batch_norm
    _verify_batch_size(input.size())
  File "/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/torch/nn/functional.py", line 2416, in _verify_batch_size
    raise ValueError("Expected more than 1 value per channel when training, got input size {}".format(size))
ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 165])

  warnings.warn(some_fits_failed_message, FitFailedWarning)
/mnt/Dados/Mestrado_Computacao_Aplicada_UFMS/documentos_dissertacao/algoritmos/precoce-ms-classification/.venv-precoce-ms/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.49444882 0.60288489 0.54905681 0.56889791 0.66504306 0.65073472
        nan]
  warnings.warn(
--------------------- RESULTS GS1 ---------------------

CSV gerado com sucesso em: ./runs/results/GS1-cv_results-15-04-2023_09:55:23.csv.
Function generate_new_csv Took 0:00:00.010403

Cross validation results:
   mean_fit_time  std_fit_time  mean_score_time  std_score_time  ... split4_test_score mean_test_score std_test_score rank_test_score
4      73.692372      0.932955         1.185614        0.037635  ...          0.668192        0.665043       0.003703               1
5       5.008563      0.273085         0.143171        0.009137  ...          0.657304        0.650735       0.006953               2
1       0.817021      0.011725         0.021857        0.001081  ...          0.604609        0.602885       0.007632               3
3      27.560970     14.538451         0.061610        0.004198  ...          0.573318        0.568898       0.011016               4
2       0.675976      0.032715         0.024691        0.002600  ...          0.549287        0.549057       0.003063               5
0       1.029464      0.777805         0.055870        0.016796  ...          0.482254        0.494449       0.006296               6
6     485.467323    420.890447         2.570712        2.099580  ...               NaN             NaN            NaN               7

[7 rows x 58 columns]
Object saved in file: ./runs/best_estimators/GS1-best_pipe-15-04-2023_09:55:23.joblib
Object saved in file: ./runs/best_estimators/best_estimator-RandomForestClassifier-15-04-2023_09:55:25.joblib
Best estimator: RandomForestClassifier(criterion='entropy', max_features=0.75,
                       n_estimators=1000, n_jobs=-1, random_state=42)
Object saved in file: ./runs/encoders_scalers/GS1-column_transformer-15-04-2023_09:55:26.joblib
Internal CV score obtained by the best set of parameters: 0.6650430612651015
Best params: {'classifier__estimator': RandomForestClassifier(criterion='entropy', max_features=0.75,
                       n_estimators=1000, n_jobs=-1, random_state=42), 'classifier__estimator__class_weight': None, 'classifier__estimator__criterion': 'entropy', 'classifier__estimator__max_depth': None, 'classifier__estimator__max_features': 0.75, 'classifier__estimator__n_estimators': 1000, 'classifier__estimator__n_jobs': -1, 'classifier__estimator__random_state': 42}
Scorer function: make_scorer(f1_score, pos_label=None, average=macro)
The number of CV splits: 5
Seconds used for refitting the best model on the whole dataset: 80.45653033256531
Whether the scorers compute several metrics: False
The number of features when fit is performed: 21
Names of features seen during fit: ['Tipificacao' 'Peso' 'QuestionarioClassificacaoEstabel' 'ILP' 'IFP'
 'ILPF' 'QuestionarioPossuiOutrosIncentiv' 'QuestionarioFabricaRacao'
 'regua de manejo' 'identificacao individual' 'rastreamento SISBOV'
 'participa de aliancas mercadolog' 'QuestionarioPraticaRecuperacaoPa'
 'Confinamento' 'Suplementacao_a_campo' 'SemiConfinamento' 'tot3m_Chuva'
 'med3m_formITUinst' 'med3m_NDVI' 'med3m_preR_milho' 'med3m_preR_boi']

!!!>> When you observe high training accuracy, but low test accuracy, it is likely that you encountered overfitting problem.
Training set score: 0.886518780703393
Test set score: 0.6583805559588629

CSV gerado com sucesso em: ./runs/results/GS1-grid_search_results-15-04-2023_09:55:32.csv.
Function generate_new_csv Took 0:00:00.002966

*****INICIO CONFUSION MATRIX DISPLAY******
Figure confusion_matrix_display-15-04-2023_09:55:35.png saved in ./plots/ directory.
*****FIM CONFUSION MATRIX DISPLAY******

Function confusion_matrix_display Took 0:00:00.807836


--- Test data performance ---
Test Acurácia: 0.7839449156100429
Test Acurácia Balanceada: 0.6799921559222787
Test Revocação: 0.8375151760420882
Test Micro Revocação: 0.7839449156100429
Test Macro Revocação: 0.6799921559222787
Test Precisão: 0.8954029204975662
Test Micro Precisão: 0.7839449156100429
Test Macro Precisão: 0.6462750338223566
Test F1: 0.8654921846411209
Test Micro F1: 0.7839449156100429
Test Macro F1: 0.6583805559588629
Test Coeficiente Kappa: 0.31985731364670433
Test Coeficiente de Correlação de Matthews: 0.32452031489748195
Test Log Loss: 0.4666931861166269
Test ROC AUC Score: 0.7650631273388592

CSV gerado com sucesso em: ./runs/results/GS1-performance_results-15-04-2023_09:55:36.csv.
Function generate_new_csv Took 0:00:00.001366

              precision    recall  f1-score   support

           0       0.40      0.52      0.45      2025
           1       0.90      0.84      0.87      9884

    accuracy                           0.78     11909
   macro avg       0.65      0.68      0.66     11909
weighted avg       0.81      0.78      0.80     11909


CSV gerado com sucesso em: ./runs/results/GS1-classification_report-15-04-2023_09:55:36.csv.
Function generate_new_csv Took 0:00:00.000980

Function run_grid_search Took 0:51:27.792421

